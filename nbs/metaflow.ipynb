{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterable\n",
    "\n",
    "from fastcore.script import call_parse\n",
    "from nbdev.export import Config, find_default_export, nbglob, read_nb\n",
    "from sciflow.data_handler import extract_param_meta\n",
    "from sciflow.params import params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciflow Notebook to MetaFlow Flow\n",
    "\n",
    "> Converts from a `sciflow` format notebook to a `metaflow` flow. \n",
    "\n",
    "Supported features:\n",
    "\n",
    "* Linear/sequential DAGs\n",
    "* Simple `Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_export.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(Config().path(\"lib_path\"), f\"{module_name}.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def titleize(name):\n",
    "    return name.title().replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert titleize(\"snake_case\") == \"SnakeCase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def rename_steps_for_metaflow(steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        if i == 0:\n",
    "            step.name = \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_steps = extract_steps(os.path.join(Config().path(\"lib_path\"), f\"_nbdev.py\"))\n",
    "assert len(no_steps) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]\n",
    "rename_steps_for_metaflow(steps)\n",
    "assert [\"start\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def indent_multiline(multiline_text, indent=1):\n",
    "    lines = multiline_text.strip().split(\"\\n\")\n",
    "    spaces = \"\".join([\"    \" for _ in range(indent)])\n",
    "    for i in range(len(lines)):\n",
    "        prefix = spaces if i > 0 else spaces + '\"\"\"'\n",
    "        lines[i] = prefix + lines[i]\n",
    "    return \"\\n\".join(lines) + '\"\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Some text\n",
    ":param param: text\n",
    "\"\"\"\n",
    "assert '    \"\"\"Some text\\n    :param param: text\"\"\"' == indent_multiline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_clustering.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(Config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def nb_to_metaflow(nb_path: Path, flow_path: Path, silent=True, track_experiment=True):\n",
    "    nb = read_nb(nb_path)\n",
    "    lib_name = Config().lib_name\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    if not module_name:\n",
    "        return\n",
    "    module_name = module_name\n",
    "    path_sep_module_name = module_name.replace(\".\", \"/\")\n",
    "    nb_name = os.path.basename(nb_path)\n",
    "    exported_module = os.path.join(\n",
    "        Config().path(\"lib_path\"), f\"{path_sep_module_name}.py\"\n",
    "    )\n",
    "    steps = extract_steps(exported_module)\n",
    "    if len(steps) == 0:\n",
    "        return\n",
    "    orig_step_names = [step.name for step in steps]\n",
    "    if len(steps) == 1:\n",
    "        steps.append(FuncDetails(\"end\", None, None, False, \"\", \"pass\"))\n",
    "    params = params_as_dict(nb_path)\n",
    "    if len(params) == 0:\n",
    "        print(f\"No params cell found for: {os.path.basename(nb_path)}\")\n",
    "    flow_class_name = f\"{titleize(extract_module_only(module_name))}Flow\"\n",
    "    rename_steps_for_metaflow(steps)\n",
    "    write_module_to_file(\n",
    "        flow_path,\n",
    "        flow_class_name,\n",
    "        lib_name,\n",
    "        module_name,\n",
    "        orig_step_names,\n",
    "        steps,\n",
    "        params,\n",
    "        track_experiment,\n",
    "    )\n",
    "    if not silent:\n",
    "        print(\n",
    "            f\"Converted {nb_name} to {flow_class_name} in: {os.path.basename(flow_path)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_module_name = \"test.module\"\n",
    "module_name = \"module\"\n",
    "path_sep_module_name = module_name.replace(\".\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_module_only(package_module_name):\n",
    "    module_name = package_module_name\n",
    "    if \".\" in module_name:\n",
    "        package_name, module_name = module_name.split(\".\")\n",
    "    return module_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"module\" == extract_module_only(module_name)\n",
    "assert \"module\" == extract_module_only(pkg_module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_module_to_file(\n",
    "    flow_path: Path,\n",
    "    flow_class_name: str,\n",
    "    lib_name: str,\n",
    "    module_name: str,\n",
    "    orig_step_names: Iterable[str],\n",
    "    steps: Iterable[FuncDetails],\n",
    "    params: dict,\n",
    "    track_experiment: bool,\n",
    "):\n",
    "    if not os.path.exists(flow_path.parent):\n",
    "        os.mkdir(flow_path.parent)\n",
    "    fq_module_name = f\"{lib_name}.{module_name}\"\n",
    "    param_meta = extract_param_meta(fq_module_name, params)\n",
    "    with open(flow_path, \"w\") as flow_file:\n",
    "        flow_file.write(\"#!/usr/bin/env python\\n\")\n",
    "        flow_file.write(\"# coding=utf-8\\n\")\n",
    "        flow_file.write(\"# SCIFLOW GENERATED FILE - EDIT COMPANION NOTEBOOK\\n\")\n",
    "        has_mf_param = any((p.has_metaflow_param for p in param_meta.values()))\n",
    "        has_json_param = any((p.is_json_type for p in param_meta.values()))\n",
    "        mf_params_import = \"from metaflow import FlowSpec, step, current\"\n",
    "        if has_mf_param:\n",
    "            mf_params_import += \", Parameter\"\n",
    "        if has_json_param:\n",
    "            mf_params_import += \", JSONType\"\n",
    "            flow_file.write(\"import json\\n\")\n",
    "        flow_file.write(mf_params_import + \"\\n\")\n",
    "        flow_file.write(f\"from {fq_module_name} import {', '.join(orig_step_names)}\\n\")\n",
    "        if len(params) > 0:\n",
    "            flow_file.write(\n",
    "                f\"from {fq_module_name} import {', '.join(params.keys())}\\n\"\n",
    "            )\n",
    "\n",
    "        if track_experiment:\n",
    "            flow_file.write(\"from sacred import Experiment\\n\")\n",
    "            flow_file.write(\"from sciflow.lake_observer import AWSLakeObserver\\n\")\n",
    "            flow_file.write(\"import time\")\n",
    "            write_observers(flow_file, module_name, Config().bucket, Config().lib_name)\n",
    "\n",
    "        flow_file.write(f\"\\n\\nclass {flow_class_name}(FlowSpec):\\n\")\n",
    "        single_indent = \"    \"\n",
    "        write_params(flow_file, param_meta, single_indent)\n",
    "        flow_file.write(f\"{single_indent}artifacts = []\\n\")\n",
    "        flow_file.write(f\"{single_indent}metrics = []\\n\")\n",
    "        flow_file.write(\"\\n\")\n",
    "        write_steps(flow_file, steps, orig_step_names, param_meta, single_indent)\n",
    "        write_track_flow(flow_file, track_experiment)\n",
    "        flow_file.write(\"\\n\")\n",
    "\n",
    "        flow_file.write('if __name__ == \"__main__\":\\n')\n",
    "        flow_file.write(f\"{single_indent}{flow_class_name}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_observers(flow_file, module_name, bucket_name, project):\n",
    "    experiment_name = extract_module_only(module_name)\n",
    "    sacred_setup = f\"\"\"\n",
    "\n",
    "ex = Experiment(\"{experiment_name}\")\n",
    "# TODO inject observers\n",
    "obs = AWSLakeObserver(\n",
    "    bucket_name=\"{bucket_name}\",\n",
    "    experiment_dir=\"experiments/{project}/{experiment_name}\",\n",
    "    region=\"eu-west-1\",\n",
    ")\n",
    "ex.observers.append(obs)\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    flow_run_id = None\n",
    "    artifacts = []\n",
    "    metrics = []\n",
    "    \"\"\"\n",
    "    flow_file.write(sacred_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_flow(flow_file, track_experiment):\n",
    "    track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        flow_info = {\n",
    "            \"flow_name\": current.flow_name,\n",
    "            \"run id\": current.run_id,\n",
    "            \"origin run id\": current.origin_run_id,\n",
    "            \"pathspec\": current.pathspec,\n",
    "            \"namespace\": current.namespace,\n",
    "            \"username\": current.username,\n",
    "            \"flow parameters\": str(current.parameter_names),\n",
    "            \"run_time_mins\": round((time.time() - self.__getattr__('start_time')) / 60.0, 1)\n",
    "        }\n",
    "    \n",
    "        run = ex.run(config_updates={'artifacts': self.__getattr__('artifacts'),\n",
    "                                    'metrics': self.__getattr__('metrics')},\n",
    "                     meta_info = flow_info)\n",
    "        \n",
    "    @ex.main\n",
    "    def track_flow(artifacts, metrics, _run):\n",
    "        for artifact in artifacts:\n",
    "            _run.add_artifact(artifact)\n",
    "        for metric_name, metric_value, step in metrics:\n",
    "            _run.log_scalar(metric_name, metric_value, step)\n",
    "    \"\"\"\n",
    "    if not track_experiment:\n",
    "        track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \"\"\"\n",
    "    flow_file.write(track_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_params(flow_file, param_meta, single_indent):\n",
    "    for param in param_meta.keys():\n",
    "        if param_meta[param].is_scalar:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default={param})\\n\"\n",
    "            )\n",
    "        elif param_meta[param].is_json_type:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=json.dumps({param}), type=JSONType)\\n\"\n",
    "            )\n",
    "        elif param_meta[param].instance_type == PosixPath:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=str({param}))\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = os.path.join(Path(\".\").resolve(), \"test\", \"test_data_handling.ipynb\")\n",
    "params = params_as_dict(nb_path)\n",
    "param_meta = extract_param_meta(\"sciflow.test.test_data_handling\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any((p.has_metaflow_param for p in param_meta.values()))\n",
    "assert any((p.is_json_type for p in param_meta.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def format_arg(arg, param_meta, returned_params):\n",
    "    if(arg in param_meta and not param_meta[arg].has_metaflow_param):\n",
    "        result = arg\n",
    "    else:\n",
    "        result = \"self.\" + arg\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_steps(flow_file, steps, orig_step_names, param_meta, single_indent):\n",
    "    returned_params = []\n",
    "    for i, step in enumerate(steps):\n",
    "        flow_file.write(f\"{single_indent}@step\\n\")\n",
    "        flow_file.write(f\"{single_indent}def {step.name}(self):\\n\")\n",
    "        if step.docstring:\n",
    "            flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "        # Check for padded step\n",
    "        if i < len(orig_step_names):\n",
    "            flow_step_args = \"\"\n",
    "            if len(step.args) > 0:\n",
    "                flow_step_args = \", \".join(\n",
    "                    [\n",
    "                        format_arg(a, param_meta, returned_params)\n",
    "                        for a in step.args.split(\",\")\n",
    "                    ]\n",
    "                )\n",
    "            if not step.has_return:\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}{orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "            else:\n",
    "                if step.return_stmt in param_meta:\n",
    "                    print(returned_params)\n",
    "                    print(param_meta)\n",
    "                    raise ValueError(\n",
    "                        f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "                    )\n",
    "                #print(step.return_stmt)\n",
    "                #returned_params.append(step.return_stmt)\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}results = {orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "                write_track_capture(flow_file)\n",
    "        if i == 0:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.start_time = time.time()\\n\"\n",
    "            )\n",
    "        if i < len(steps):\n",
    "            next_step = \"end\" if i == len(steps) - 1 else steps[i + 1].name\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.next(self.{next_step})\\n\"\n",
    "            )\n",
    "        flow_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_capture(flow_file):\n",
    "    flow_file.write(\n",
    "        f\"\"\"\n",
    "        for key in results.keys():\n",
    "            if key in self.__dict__:\n",
    "                self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "            else:\n",
    "                self.__dict__[key] = results[key]\n",
    "\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_module_name(nb_path):\n",
    "    nb = read_nb(nb_path)\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    return module_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = Path(\n",
    "    os.path.join(\n",
    "        Path(\".\").resolve(),\n",
    "        \"test\",\n",
    "        \"flows\",\n",
    "        f\"{get_module_name(nb_path).split('.')[-1]}.py\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    Path(\"/home/jovyan/git/sciflow/nbs/test/flows/test_data_handling.py\") == flow_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(nb_path, flow_path, silent=False, track_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_clustering.ipynb to TestClusteringFlow in: test_clustering.py\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(Path(\"/home/jovyan/git/sciflow/nbs/test/test_clustering.ipynb\"), \n",
    "               Path(\"/home/jovyan/git/sciflow/nbs/test/flows/test_clustering.py\"), \n",
    "               silent=False, track_experiment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore notebooks without Sciflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\"packaging.ipynb\", flow_path, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def generate_flows(config: Config):\n",
    "    flows_dir = config.path(\"flows_path\")\n",
    "    nb_paths = nbglob(recursive=True)\n",
    "    for nb_path in nb_paths:\n",
    "        flow_module_name = os.path.basename(nb_path).replace(\"ipynb\", \"py\")\n",
    "        nb_to_metaflow(\n",
    "            nb_path, Path(os.path.join(flows_dir, flow_module_name)), silent=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO revisit END PADDING logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No params cell found for: test_clustering_no_params.ipynb\n",
      "Converted test_clustering_no_params.ipynb to TestClusteringNoParamsFlow in: test_clustering_no_params.py\n",
      "Converted test_clustering.ipynb to TestClusteringFlow in: test_clustering.py\n",
      "Converted test_export.ipynb to TestExportFlow in: test_export.py\n",
      "Converted test_module.ipynb to TestModuleFlow in: test_module.py\n",
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "generate_flows(Config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_generate():\n",
    "    generate_flows(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_flows(config, flow_command=\"show\"):\n",
    "    flow_results = {}\n",
    "    flows_dir = config.path(\"flows_path\")\n",
    "    for flow_path in os.listdir(flows_dir):\n",
    "        flow_name = os.path.basename(flow_path)\n",
    "        if flow_path.endswith(\".py\"):\n",
    "            ret_code, output = check_flow(\n",
    "                flows_dir, flow_path, flow_command=flow_command\n",
    "            )\n",
    "            flow_results[flow_name] = ret_code, output\n",
    "            if ret_code == 0:\n",
    "                print(f\"Flow: {flow_name} verified\")\n",
    "            else:\n",
    "                print(f\"Flow: {flow_name} verification failed\\nDetails:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def prep_mf_env():\n",
    "    if \"USER\" not in os.environ:\n",
    "        try:\n",
    "            os.environ[\"USER\"] = os.environ[\"GIT_COMMITTER_NAME\"]\n",
    "        except KeyError:\n",
    "            raise EnvironmentError(\n",
    "                \"Metaflow requires a known user for tracked execution. Add USER or GIT_COMMITTER_NAME to Jupyter environment variables\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_shell_cmd(script):\n",
    "    pipe = subprocess.Popen(\n",
    "        \"%s\" % script, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True\n",
    "    )\n",
    "    output = pipe.communicate()[0]\n",
    "    return pipe, output.decode(\"utf-8\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_flow(flows_dir, flow_module, flow_command=\"show\"):\n",
    "    prep_mf_env()\n",
    "    script = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command}\"\n",
    "    pipe, output = run_shell_cmd(script)\n",
    "    return pipe.returncode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_module.py verified\n",
      "Flow: test_clustering_no_params.py verified\n",
      "Flow: test_clustering.py verified\n",
      "Flow: test_data_handling.py verified\n",
      "Flow: test_export.py verified\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "check_flows(Config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_module.py verified\n",
      "Flow: test_clustering_no_params.py verification failed\n",
      "Details:\n",
      "Metaflow 2.2.7 executing TestClusteringNoParamsFlow for user:e02079\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "2021-04-21 13:56:25.989 Workflow starting (run-id 1619013385984786):\n",
      "2021-04-21 13:56:25.993 [1619013385984786/start/1 (pid 2765)] Task is starting.\n",
      "2021-04-21 13:56:28.100 [1619013385984786/start/1 (pid 2765)] Task finished successfully.\n",
      "2021-04-21 13:56:28.107 [1619013385984786/preprocess/2 (pid 2780)] Task is starting.\n",
      "2021-04-21 13:56:30.006 [1619013385984786/preprocess/2 (pid 2780)] <flow TestClusteringNoParamsFlow step preprocess> failed:\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     Internal error\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)] Traceback (most recent call last):\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/metaflow/cli.py\", line 930, in main\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     start(auto_envvar_prefix='METAFLOW', obj=state)\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     return self.main(args, kwargs)\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/core.py\", line 782, in main\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     rv = self.invoke(ctx)\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]     return ctx.invoke(self.callback, ctx.params)\n",
      "2021-04-21 13:56:30.007 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\n",
      "2021-04-21 13:56:30.008 [1619013385984786/preprocess/2 (pid 2780)]     return callback(args, kwargs)\n",
      "2021-04-21 13:56:30.008 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/click/decorators.py\", line 33, in new_func\n",
      "2021-04-21 13:56:30.008 [1619013385984786/preprocess/2 (pid 2780)]     return f(get_current_context().obj, args, kwargs)\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/metaflow/cli.py\", line 447, in step\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]     max_user_code_retries)\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/metaflow/task.py\", line 396, in run_step\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]     self._exec_step_function(step_func)\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/metaflow/task.py\", line 47, in _exec_step_function\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]     step_function()\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/git/sciflow/nbs/test/flows/test_clustering_no_params.py\", line 38, in preprocess\n",
      "2021-04-21 13:56:30.180 [1619013385984786/preprocess/2 (pid 2780)]     results = preprocess(self.dremio_access, self.model_level, self.min_date, self.traffic_percent)\n",
      "2021-04-21 13:56:30.181 [1619013385984786/preprocess/2 (pid 2780)]   File \"/home/jovyan/envs/discovery/lib/python3.7/site-packages/metaflow/flowspec.py\", line 129, in __getattr__\n",
      "2021-04-21 13:56:30.181 [1619013385984786/preprocess/2 (pid 2780)]     (self.name, name))\n",
      "2021-04-21 13:56:30.181 [1619013385984786/preprocess/2 (pid 2780)] AttributeError: Flow TestClusteringNoParamsFlow has no attribute 'dremio_access'\n",
      "2021-04-21 13:56:30.181 [1619013385984786/preprocess/2 (pid 2780)] \n",
      "2021-04-21 13:56:30.182 [1619013385984786/preprocess/2 (pid 2780)] Task failed.\n",
      "2021-04-21 13:56:30.182 Workflow failed.\n",
      "2021-04-21 13:56:30.182 Terminating 0 active tasks...\n",
      "2021-04-21 13:56:30.182 Flushing logs...\n",
      "    Step failure:\n",
      "    Step preprocess (task-id 2) failed.\n",
      "Flow: test_clustering.py verified\n",
      "Flow: test_data_handling.py verified\n",
      "Flow: test_export.py verified\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "check_flows(Config(cfg_name=\"test/settings.ini\"), \"--no-pylint run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_flows():\n",
    "    check_flows(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_flows():\n",
    "    check_flows(Config(), \"--no-pylint run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-discovery]",
   "language": "python",
   "name": "conda-env-jovyan-discovery-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
