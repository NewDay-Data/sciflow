{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterable\n",
    "import asyncio\n",
    "\n",
    "from fastcore.script import call_parse\n",
    "from nbdev.export import Config, find_default_export, nbglob, read_nb\n",
    "from sciflow.data_handler import extract_param_meta\n",
    "from sciflow.params import params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciflow Notebook to MetaFlow Flow\n",
    "\n",
    "> Converts from a `sciflow` format notebook to a `metaflow` flow. \n",
    "\n",
    "Supported features:\n",
    "\n",
    "* Linear/sequential DAGs\n",
    "* Simple `Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_export.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(Config().path(\"lib_path\"), f\"{module_name}.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def titleize(name):\n",
    "    return name.title().replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert titleize(\"snake_case\") == \"SnakeCase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def rename_steps_for_metaflow(steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        if i == 0:\n",
    "            step.name = \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_steps = extract_steps(os.path.join(Config().path(\"lib_path\"), f\"_nbdev.py\"))\n",
    "assert len(no_steps) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]\n",
    "rename_steps_for_metaflow(steps)\n",
    "assert [\"start\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def indent_multiline(multiline_text, indent=1):\n",
    "    lines = multiline_text.strip().split(\"\\n\")\n",
    "    spaces = \"\".join([\"    \" for _ in range(indent)])\n",
    "    for i in range(len(lines)):\n",
    "        prefix = spaces if i > 0 else spaces + '\"\"\"'\n",
    "        lines[i] = prefix + lines[i]\n",
    "    return \"\\n\".join(lines) + '\"\"\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Some text\n",
    ":param param: text\n",
    "\"\"\"\n",
    "assert '    \"\"\"Some text\\n    :param param: text\"\"\"' == indent_multiline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_clustering.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(Config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def nb_to_metaflow(nb_path: Path, flow_path: Path, silent=True, track_experiment=True):\n",
    "    nb = read_nb(nb_path)\n",
    "    lib_name = Config().lib_name\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    if not module_name:\n",
    "        return\n",
    "    module_name = module_name\n",
    "    path_sep_module_name = module_name.replace(\".\", \"/\")\n",
    "    nb_name = os.path.basename(nb_path)\n",
    "    exported_module = os.path.join(\n",
    "        Config().path(\"lib_path\"), f\"{path_sep_module_name}.py\"\n",
    "    )\n",
    "    steps = extract_steps(exported_module)\n",
    "    if len(steps) == 0:\n",
    "        return\n",
    "    orig_step_names = [step.name for step in steps]\n",
    "    if len(steps) == 1:\n",
    "        steps.append(FuncDetails(\"end\", None, None, False, \"\", \"pass\"))\n",
    "    params = params_as_dict(nb_path)\n",
    "    if len(params) == 0:\n",
    "        print(f\"No params cell found for: {os.path.basename(nb_path)}\")\n",
    "    flow_class_name = f\"{titleize(extract_module_only(module_name))}Flow\"\n",
    "    rename_steps_for_metaflow(steps)\n",
    "    write_module_to_file(\n",
    "        flow_path,\n",
    "        flow_class_name,\n",
    "        lib_name,\n",
    "        module_name,\n",
    "        orig_step_names,\n",
    "        steps,\n",
    "        params,\n",
    "        track_experiment,\n",
    "    )\n",
    "    if not silent:\n",
    "        print(\n",
    "            f\"Converted {nb_name} to {flow_class_name} in: {os.path.basename(flow_path)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_module_name = \"test.module\"\n",
    "module_name = \"module\"\n",
    "path_sep_module_name = module_name.replace(\".\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_module_only(package_module_name):\n",
    "    module_name = package_module_name\n",
    "    if \".\" in module_name:\n",
    "        package_name, module_name = module_name.split(\".\")\n",
    "    return module_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"module\" == extract_module_only(module_name)\n",
    "assert \"module\" == extract_module_only(pkg_module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_module_to_file(\n",
    "    flow_path: Path,\n",
    "    flow_class_name: str,\n",
    "    lib_name: str,\n",
    "    module_name: str,\n",
    "    orig_step_names: Iterable[str],\n",
    "    steps: Iterable[FuncDetails],\n",
    "    params: dict,\n",
    "    track_experiment: bool,\n",
    "):\n",
    "    if not os.path.exists(flow_path.parent):\n",
    "        os.mkdir(flow_path.parent)\n",
    "    fq_module_name = f\"{lib_name}.{module_name}\"\n",
    "    param_meta = extract_param_meta(fq_module_name, params)\n",
    "    with open(flow_path, \"w\") as flow_file:\n",
    "        flow_file.write(\"#!/usr/bin/env python\\n\")\n",
    "        flow_file.write(\"# coding=utf-8\\n\")\n",
    "        flow_file.write(\"# SCIFLOW GENERATED FILE - EDIT COMPANION NOTEBOOK\\n\")\n",
    "        has_mf_param = any((p.has_metaflow_param for p in param_meta.values()))\n",
    "        has_json_param = any((p.is_json_type for p in param_meta.values()))\n",
    "        mf_params_import = \"from metaflow import FlowSpec, step, current\"\n",
    "        if has_mf_param:\n",
    "            mf_params_import += \", Parameter\"\n",
    "        if has_json_param:\n",
    "            mf_params_import += \", JSONType\"\n",
    "            flow_file.write(\"import json\\n\")\n",
    "        flow_file.write(mf_params_import + \"\\n\")\n",
    "        flow_file.write(f\"from {fq_module_name} import {', '.join(orig_step_names)}\\n\")\n",
    "        if len(params) > 0:\n",
    "            flow_file.write(\n",
    "                f\"from {fq_module_name} import {', '.join(params.keys())}\\n\"\n",
    "            )\n",
    "\n",
    "        if track_experiment:\n",
    "            flow_file.write(\"from sacred import Experiment\\n\")\n",
    "            flow_file.write(\"from sciflow.lake_observer import AWSLakeObserver\\n\")\n",
    "            flow_file.write(\"import time\")\n",
    "            write_observers(flow_file, module_name, Config().bucket, Config().lib_name)\n",
    "\n",
    "        flow_file.write(f\"\\n\\nclass {flow_class_name}(FlowSpec):\\n\")\n",
    "        single_indent = \"    \"\n",
    "        write_params(flow_file, param_meta, single_indent)\n",
    "        flow_file.write(f\"{single_indent}artifacts = []\\n\")\n",
    "        flow_file.write(f\"{single_indent}metrics = []\\n\")\n",
    "        flow_file.write(\"\\n\")\n",
    "        write_steps(flow_file, steps, orig_step_names, param_meta, single_indent)\n",
    "        write_track_flow(flow_file, track_experiment)\n",
    "        flow_file.write(\"\\n\")\n",
    "\n",
    "        flow_file.write('if __name__ == \"__main__\":\\n')\n",
    "        flow_file.write(f\"{single_indent}{flow_class_name}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_observers(flow_file, module_name, bucket_name, project):\n",
    "    experiment_name = extract_module_only(module_name)\n",
    "    sacred_setup = f\"\"\"\n",
    "\n",
    "ex = Experiment(\"{experiment_name}\")\n",
    "# TODO inject observers\n",
    "obs = AWSLakeObserver(\n",
    "    bucket_name=\"{bucket_name}\",\n",
    "    experiment_dir=\"experiments/{project}/{experiment_name}\",\n",
    "    region=\"eu-west-1\",\n",
    ")\n",
    "ex.observers.append(obs)\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    flow_run_id = None\n",
    "    artifacts = []\n",
    "    metrics = []\n",
    "    \"\"\"\n",
    "    flow_file.write(sacred_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_flow(flow_file, track_experiment):\n",
    "    track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        flow_info = {\n",
    "            \"flow_name\": current.flow_name,\n",
    "            \"run id\": current.run_id,\n",
    "            \"origin run id\": current.origin_run_id,\n",
    "            \"pathspec\": current.pathspec,\n",
    "            \"namespace\": current.namespace,\n",
    "            \"username\": current.username,\n",
    "            \"flow parameters\": str(current.parameter_names),\n",
    "            \"run_time_mins\": round((time.time() - self.__getattr__('start_time')) / 60.0, 1)\n",
    "        }\n",
    "    \n",
    "        run = ex.run(config_updates={'artifacts': self.__getattr__('artifacts'),\n",
    "                                    'metrics': self.__getattr__('metrics')},\n",
    "                     meta_info = flow_info)\n",
    "        \n",
    "    @ex.main\n",
    "    def track_flow(artifacts, metrics, _run):\n",
    "        for artifact in artifacts:\n",
    "            _run.add_artifact(artifact)\n",
    "        for metric_name, metric_value, step in metrics:\n",
    "            _run.log_scalar(metric_name, metric_value, step)\n",
    "    \"\"\"\n",
    "    if not track_experiment:\n",
    "        track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \"\"\"\n",
    "    flow_file.write(track_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_params(flow_file, param_meta, single_indent):\n",
    "    for param in param_meta.keys():\n",
    "        if param_meta[param].is_scalar:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default={param})\\n\"\n",
    "            )\n",
    "        elif param_meta[param].is_json_type:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=json.dumps({param}), type=JSONType)\\n\"\n",
    "            )\n",
    "        elif param_meta[param].instance_type == PosixPath:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=str({param}))\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = os.path.join(Path(\".\").resolve(), \"test\", \"test_data_handling.ipynb\")\n",
    "params = params_as_dict(nb_path)\n",
    "param_meta = extract_param_meta(\"sciflow.test.test_data_handling\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any((p.has_metaflow_param for p in param_meta.values()))\n",
    "assert any((p.is_json_type for p in param_meta.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def format_arg(arg, param_meta):\n",
    "    if arg in param_meta and not param_meta[arg].has_metaflow_param:\n",
    "        result = arg\n",
    "    else:\n",
    "        result = \"self.\" + arg\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_steps(flow_file, steps, orig_step_names, param_meta, single_indent):\n",
    "    for i, step in enumerate(steps):\n",
    "        flow_file.write(f\"{single_indent}@step\\n\")\n",
    "        flow_file.write(f\"{single_indent}def {step.name}(self):\\n\")\n",
    "        if step.docstring:\n",
    "            flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "        # Check for padded step\n",
    "        if i < len(orig_step_names):\n",
    "            flow_step_args = \"\"\n",
    "            if len(step.args) > 0:\n",
    "                flow_step_args = \", \".join(\n",
    "                    [\n",
    "                        format_arg(a, param_meta)\n",
    "                        for a in step.args.split(\",\")\n",
    "                    ]\n",
    "                )\n",
    "            if not step.has_return:\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}{orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "            else:\n",
    "                if step.return_stmt in param_meta:\n",
    "                    raise ValueError(\n",
    "                        f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "                    )\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}results = {orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "                write_track_capture(flow_file)\n",
    "        if i == 0:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.start_time = time.time()\\n\"\n",
    "            )\n",
    "        if i < len(steps):\n",
    "            next_step = \"end\" if i == len(steps) - 1 else steps[i + 1].name\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.next(self.{next_step})\\n\"\n",
    "            )\n",
    "        flow_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_capture(flow_file):\n",
    "    flow_file.write(\n",
    "        f\"\"\"\n",
    "        for key in results.keys():\n",
    "            if key in self.__dict__:\n",
    "                self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "            else:\n",
    "                self.__dict__[key] = results[key]\n",
    "\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_module_name(nb_path):\n",
    "    nb = read_nb(nb_path)\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    return module_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_path(nb_path):\n",
    "    return Path(\n",
    "        os.path.join(Config().path(\"flows_path\"), \n",
    "        f\"{get_module_name(nb_path).split('.')[-1]}.py\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(Path('/home/jovyan/git/sciflow/nbs/test/flows/test_data_handling.py') == get_flows_path(nb_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = Path(\n",
    "    os.path.join(\n",
    "        Path(\".\").resolve(),\n",
    "        \"test\",\n",
    "        \"flows\",\n",
    "        f\"{get_module_name(nb_path).split('.')[-1]}.py\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    Path(os.path.join(Path(\".\").resolve(), \"test\", \"flows\", \"test_data_handling.py\",))\n",
    "    == flow_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(nb_path, flow_path, silent=False, track_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_clustering.ipynb to TestClusteringFlow in: test_clustering.py\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(\n",
    "    Path(\"/home/jovyan/git/sciflow/nbs/test/test_clustering.ipynb\"),\n",
    "    Path(\"/home/jovyan/git/sciflow/nbs/test/flows/test_clustering.py\"),\n",
    "    silent=False,\n",
    "    track_experiment=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore notebooks without Sciflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\"packaging.ipynb\", flow_path, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def generate_flows(config: Config):\n",
    "    flows_dir = config.path(\"flows_path\")\n",
    "    nb_paths = nbglob(recursive=True)\n",
    "    for nb_path in nb_paths:\n",
    "        flow_module_name = os.path.basename(nb_path).replace(\"ipynb\", \"py\")\n",
    "        nb_to_metaflow(\n",
    "            nb_path, Path(os.path.join(flows_dir, flow_module_name)), silent=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO revisit END PADDING logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No params cell found for: test_clustering_no_params.ipynb\n",
      "Converted test_clustering_no_params.ipynb to TestClusteringNoParamsFlow in: test_clustering_no_params.py\n",
      "Converted test_clustering.ipynb to TestClusteringFlow in: test_clustering.py\n",
      "Converted test_export.ipynb to TestExportFlow in: test_export.py\n",
      "Converted test_module.ipynb to TestModuleFlow in: test_module.py\n",
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "generate_flows(Config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_generate():\n",
    "    generate_flows(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_flows(config, flow_command=\"show\", ignore_suffix=\"_no_params.py\"):\n",
    "    flow_results = {}\n",
    "    flows_dir = config.path(\"flows_path\")\n",
    "    if ignore_suffix:\n",
    "        flow_paths = [p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)]\n",
    "    else:\n",
    "        flow_paths = os.listdir(flows_dir)\n",
    "    for flow_path in flow_paths:\n",
    "        flow_name = os.path.basename(flow_path)\n",
    "        if flow_path.endswith(\".py\"):\n",
    "            ret_code, output = check_flow(\n",
    "                flows_dir, flow_path, flow_command=flow_command\n",
    "            )\n",
    "            flow_results[flow_name] = ret_code, output\n",
    "            if ret_code == 0:\n",
    "                print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def prep_mf_env():\n",
    "    if \"USER\" not in os.environ:\n",
    "        try:\n",
    "            os.environ[\"USER\"] = os.environ[\"GIT_COMMITTER_NAME\"]\n",
    "        except KeyError:\n",
    "            raise EnvironmentError(\n",
    "                \"Metaflow requires a known user for tracked execution. Add USER or GIT_COMMITTER_NAME to Jupyter environment variables\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_shell_cmd(script):\n",
    "    pipe = subprocess.Popen(\n",
    "        \"%s\" % script, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True\n",
    "    )\n",
    "    output = pipe.communicate()[0]\n",
    "    return pipe, output.decode(\"utf-8\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_flow(flows_dir, flow_module, flow_command=\"show\", params=None):\n",
    "    prep_mf_env()\n",
    "    if params:\n",
    "        args = ' '.join([f'--{p[0]} {p[1]}' for p in params])\n",
    "        script = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command} {args}\"\n",
    "    else:\n",
    "        script = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command}\"\n",
    "    pipe, output = run_shell_cmd(script)\n",
    "    return pipe.returncode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [('speed', 'fast'), ('traffic_percent', 10)]\n",
    "assert('--speed fast --traffic_percent 10' == ' '.join([f'--{p[0]} {p[1]}' for p in params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_module.py show verified\n",
      "Flow: test_clustering_no_params.py show verified\n",
      "Flow: test_clustering.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_export.py show verified\n"
     ]
    }
   ],
   "source": [
    "check_flows(Config(cfg_name=\"test/settings.ini\"), ignore_suffix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_clustering.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_export.py --no-pylint run verified\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "check_flows(Config(cfg_name=\"test/settings.ini\"), \"--no-pylint run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flow(flow_path, params=None):\n",
    "    print(f'Running flow: {os.path.basename(flow_path)}')\n",
    "    return check_flow(flow_path.parent, os.path.basename(flow_path), flow_command=\"--no-pylint run\", params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running flow: test_clustering.py\n",
      "Metaflow 2.2.7 executing TestClusteringFlow for user:e02079\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "2021-04-21 16:31:18.545 Workflow starting (run-id 1619022678541832):\n",
      "2021-04-21 16:31:18.549 [1619022678541832/start/1 (pid 14778)] Task is starting.\n",
      "2021-04-21 16:31:20.810 [1619022678541832/start/1 (pid 14778)] Task finished successfully.\n",
      "2021-04-21 16:31:20.817 [1619022678541832/preprocess/2 (pid 14793)] Task is starting.\n",
      "2021-04-21 16:31:49.716 [1619022678541832/preprocess/2 (pid 14793)] Task finished successfully.\n",
      "2021-04-21 16:31:49.723 [1619022678541832/fit/3 (pid 14830)] Task is starting.\n",
      "2021-04-21 16:31:52.031 [1619022678541832/fit/3 (pid 14830)] Task finished successfully.\n",
      "2021-04-21 16:31:52.038 [1619022678541832/evaluate/4 (pid 14845)] Task is starting.\n",
      "2021-04-21 16:31:54.194 [1619022678541832/evaluate/4 (pid 14845)] Task finished successfully.\n",
      "2021-04-21 16:31:54.201 [1619022678541832/end/5 (pid 14860)] Task is starting.\n",
      "2021-04-21 16:31:56.202 [1619022678541832/end/5 (pid 14860)] INFO:test_clustering:Running command 'track_flow'\n",
      "2021-04-21 16:31:56.631 [1619022678541832/end/5 (pid 14860)] INFO:test_clustering:Started run with ID \"25\"\n",
      "2021-04-21 16:31:56.799 [1619022678541832/end/5 (pid 14860)] INFO:test_clustering:Completed after 0:00:01\n",
      "2021-04-21 16:31:57.395 [1619022678541832/end/5 (pid 14860)] Task finished successfully.\n",
      "2021-04-21 16:31:57.396 Done!\n"
     ]
    }
   ],
   "source": [
    "ret_code, output = run_flow(Path('/home/jovyan/git/sciflow/nbs/test/flows/test_clustering.py'), \n",
    "         params=[('traffic_percent', 10), ('speed', 'fast')]\n",
    "        )\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_flow_task(flow_path, params=None):\n",
    "    flows_dir = flow_path.parent\n",
    "    flow_module = os.path.basename(flow_path)\n",
    "    flow_command=\"--no-pylint run\"\n",
    "    prep_mf_env()\n",
    "    if params:\n",
    "        args = ' '.join([f'--{p[0]} {p[1]}' for p in params])\n",
    "        cmd = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command} {args}\"\n",
    "    else:\n",
    "        cmd = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command}\"\n",
    "    proc = await asyncio.create_subprocess_shell(\n",
    "        cmd,\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE)\n",
    "\n",
    "    stdout, stderr = await proc.communicate()\n",
    "\n",
    "    print(f'[{cmd!r} exited with {proc.returncode}]')\n",
    "    if stdout:\n",
    "        print(f'[stdout]\\n{stdout.decode(\"utf-8\").strip()}')\n",
    "    if stderr:\n",
    "        print(f'[stderr]\\n{stderr.decode(\"utf-8\").strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_flow_async(nb_path, params=None):\n",
    "    flow_path = get_flow_path(nb_path)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(run_flow_task(flow_path, params))\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = run_flow_async('/home/jovyan/git/sciflow/nbs/test/test_clustering.ipynb',\n",
    "                     params=[('traffic_percent', 10), ('speed', 'fast')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending coro=<run_flow_task() running at <ipython-input-310-acf846e28e3e>:16> wait_for=<_GatheringFuture pending cb=[<TaskWakeupMethWrapper object at 0x7f68e9847390>()]>>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_flows():\n",
    "    check_flows(Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_flows():\n",
    "    check_flows(Config(), \"--no-pylint run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-discovery]",
   "language": "python",
   "name": "conda-env-jovyan-discovery-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
