{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parse_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from nbdev.export import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_step_code(\n",
    "    module_path: Path,\n",
    "    export_comments=(\"# cell\", \"# internal cell\", \"# comes from\"),\n",
    "    remove_comment_lines=True,\n",
    "):\n",
    "    with open(module_path, \"r\") as module_file:\n",
    "        lines = module_file.readlines()\n",
    "    lines = pd.Series(lines)\n",
    "    step_code = {}\n",
    "    active_step = None\n",
    "    for l in lines.tolist():\n",
    "        if l.lower().startswith(\"# step\"):\n",
    "            active_step = l.split(\":\")[1].strip()\n",
    "        elif l.lower().startswith(export_comments):\n",
    "            active_step = None\n",
    "        if l.startswith(\"#\") and remove_comment_lines:\n",
    "            continue\n",
    "        if active_step:\n",
    "            if not active_step in step_code:\n",
    "                step_code[active_step] = []\n",
    "            step_code[active_step].append(l)\n",
    "    for key in step_code.keys():\n",
    "        step_code[key] = \"\".join(step_code[key])\n",
    "    return step_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_module = os.path.join(get_config().path(\"lib_path\"), \"test\", \"test_multistep.py\")\n",
    "step_code = extract_step_code(test_module)\n",
    "step_names = step_code.keys()\n",
    "assert [\"first\", \"preprocess\", \"fit\", \"evaluate\"] == list(step_names)\n",
    "assert all(\n",
    "    [\n",
    "        len([i for i in range(len(sc)) if sc.startswith(\"def\", i)]) == 1\n",
    "        for sc in step_code.values()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_module = os.path.join(get_config().path(\"lib_path\"), \"test\", \"test_export.py\")\n",
    "step_code = extract_step_code(test_module)\n",
    "step_names = step_code.keys()\n",
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == list(step_names)\n",
    "assert not step_code[\"first\"].startswith(\"#\")\n",
    "assert extract_step_code(test_module, remove_comment_lines=False)[\"first\"].startswith(\n",
    "    \"#\"\n",
    ")\n",
    "assert all(\n",
    "    [\n",
    "        len([i for i in range(len(sc)) if sc.startswith(\"def\", i)]) == 1\n",
    "        for sc in step_code.values()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class FuncLister(ast.NodeVisitor):\n",
    "    has_return = False\n",
    "\n",
    "    def visit_Return(self, node):\n",
    "        self.has_return = True\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.name = node.name\n",
    "        self.docstring = ast.get_docstring(node)\n",
    "        self.args = node.args.args\n",
    "        self.arg_names = [a.arg for a in node.args.args]\n",
    "        self.generic_visit(node)\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, width=120, compact=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FuncDetails:\n",
    "    name: str\n",
    "    docstring: str\n",
    "    args: str\n",
    "    has_return: bool\n",
    "    return_stmt: str\n",
    "    code: str\n",
    "\n",
    "    def __repr__(self):\n",
    "        return pp.pformat(\n",
    "            f\"FuncDetails(name={self.name},args={self.args},has_return={self.has_return}):\\n{self.code.strip()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_func = \"\"\"\n",
    "def some_func():\n",
    "    print 1\n",
    "\"\"\"\n",
    "assert (\n",
    "    FuncDetails(\"a\", None, \"an_arg\", True, \"return True\", some_func).__repr__()\n",
    "    == \"'FuncDetails(name=a,args=an_arg,has_return=True):\\\\ndef some_func():\\\\n    print 1'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_return_stmt(func_name, code):\n",
    "    return_stmt = [\n",
    "        l.strip().split(\"return\")[1].strip()\n",
    "        for l in code.splitlines()\n",
    "        if l.strip().startswith(\"return\")\n",
    "    ]\n",
    "    if len(return_stmt) == 0:\n",
    "        return\n",
    "    return_stmt = return_stmt[0]\n",
    "    is_named_variable = bool(re.search(\"^[a-zA-Z]+[a-zA-Z0-9_]*$\", return_stmt))\n",
    "    if not is_named_variable:\n",
    "        raise NotImplementedError(\n",
    "            f\"Inline return statements are not supported. Assign the return value of {func_name} to a variable before returning.\"\n",
    "        )\n",
    "    return return_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_return = \"\"\"\n",
    "def preprocess(conn, model_level, min_date, traffic_percent):\n",
    "    data = get_utterances(conn, model_level, min_date, traffic_percent)\n",
    "    button_filter = get_button_responses_filter(conn)\n",
    "    user_texts = data[~data.Utterance.isin(button_filter)].copy()\n",
    "    documents = {\"some_field\": user_texts.Utterance.tolist()}\n",
    "    return documents\n",
    "\"\"\"\n",
    "\n",
    "multiple_key_return = \"\"\"\n",
    "def evaluate(model):\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "\n",
    "    topic_contains_non_empty_words = all([len(tw) > 0 for tw in topic_words])\n",
    "    word_scores_in_range = word_scores.min() >= 0.0 and word_scores.max() <= 1.0\n",
    "    as_many_items_as_topics = (\n",
    "        model.get_num_topics() == len(topic_words) == word_scores.shape[0]\n",
    "    )\n",
    "    word_summaries = (\n",
    "        topic_contains_non_empty_words\n",
    "        and word_scores_in_range\n",
    "        and as_many_items_as_topics\n",
    "    )\n",
    "    # You can add artifacts in a step that will be saved to block storage. Add the paths to the file on the local filesystem\n",
    "    # and the artifact will be uploaded to remote storage.\n",
    "    sample_df = pd.DataFrame(\n",
    "        {\"a\": model.get_topic_sizes()[0], \"b\": model.get_topic_sizes()[1]}\n",
    "    )\n",
    "    sample_df.to_csv(\"/tmp/dataframe_artifact.csv\", index=False)\n",
    "    artifacts = [\"/tmp/dataframe_artifact.csv\"]\n",
    "    # You can add step metrics too this time just add a list of 3-tuples where tuple order = (name, value, step)\n",
    "    metrics = [(\"mae\", 100, 0), (\"mae\", 67, 1), (\"mae\", 32, 2)]\n",
    "    results = {\n",
    "        \"word_summaries\": word_summaries,\n",
    "        \"artifacts\": artifacts,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "    return results\n",
    "\"\"\"\n",
    "unnamed_return = \"\"\"\n",
    "def fit(documents, workers=workers, speed=\"fast-learn\"):\n",
    "    return {Top2Vec(documents, workers=workers, speed=speed)}\n",
    "\"\"\"\n",
    "\n",
    "number_return = \"\"\"\n",
    "def fit(documents, workers=workers, speed=\"fast-learn\"):\n",
    "    return 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_code_block = \"\"\"\n",
    "def train(input_path: Path, model_path: Path):\n",
    "    \\\"\"\"Function docs\\\"\"\"\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    print(f'Training {model_path} on {input_path}...')\n",
    "    time.sleep(1)\n",
    "\"\"\"\n",
    "\n",
    "invalid_code_block = \"\"\"\n",
    "def train(input_path: Path, model_path: Path):\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    print(f'Training {model_path} on {input_path}...')\n",
    "    time.slurp(1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_return_stmt(\"train\", named_return) == \"documents\"\n",
    "assert extract_return_stmt(\"train\", valid_code_block) is None\n",
    "try:\n",
    "    extract_return_stmt(\"train\", number_return)\n",
    "except NotImplementedError as e:\n",
    "    assert e is not None\n",
    "try:\n",
    "    extract_return_stmt(\"train\", unnamed_return)\n",
    "except NotImplementedError as e:\n",
    "    assert e is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def parse_step(step_code: str):\n",
    "    tree = ast.parse(step_code)\n",
    "    lister = FuncLister()\n",
    "    lister.visit(tree)\n",
    "    if \"name\" not in lister.__dict__:\n",
    "        raise (\n",
    "            ValueError(\"Step must have a single valid function; check step definition\")\n",
    "        )\n",
    "    return FuncDetails(\n",
    "        lister.name,\n",
    "        lister.docstring,\n",
    "        \",\".join(lister.arg_names),\n",
    "        lister.has_return,\n",
    "        extract_return_stmt(lister.name, step_code),\n",
    "        step_code,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_return_var_names(step):\n",
    "    results_index = step.code.find(f\"{step.return_stmt} =\")\n",
    "    if results_index == -1:\n",
    "        return []\n",
    "\n",
    "    keys = []\n",
    "    for l in step.code[results_index:].split(\"\\n\"):\n",
    "        if l.strip().find(\":\") > -1:\n",
    "            key_prefix = l.split(\":\")[0]\n",
    "            key = key_prefix[key_prefix.find(\"{\") + 1 :]\n",
    "            keys.append(key.strip(' \",'))\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"some_field\"] == extract_return_var_names(parse_step(named_return))\n",
    "assert [\"word_summaries\", \"artifacts\", \"metrics\"] == extract_return_var_names(\n",
    "    parse_step(multiple_key_return)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"documents\" == parse_step(named_return).return_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dets = parse_step(valid_code_block)\n",
    "assert func_dets.name == \"train\"\n",
    "assert func_dets.args == \",\".join([\"input_path\", \"model_path\"])\n",
    "assert not func_dets.has_return\n",
    "assert type(func_dets.code) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_steps(module_path: Path):\n",
    "    step_code = extract_step_code(module_path)\n",
    "    steps = [parse_step(step_code[k]) for k in step_code.keys()]\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FuncDetails(name=first,args=some_params,has_return=False):\\n'\n",
       "  'def first(some_params: int):\\n'\n",
       "  '    \"\"\"\\n'\n",
       "  '    This the entrypoint.\\n'\n",
       "  '\\n'\n",
       "  '    :param some_params: this is a first param\\n'\n",
       "  '    :returns: this is a description of what is returned\\n'\n",
       "  '    \"\"\"\\n'\n",
       "  '    print(some_params)'),\n",
       " ('FuncDetails(name=preprocess,args=input_path,has_return=False):\\n'\n",
       "  'def preprocess(input_path: str):\\n'\n",
       "  '    \"\"\"Pre-process the input data\"\"\"\\n'\n",
       "  '    import time\\n'\n",
       "  '\\n'\n",
       "  '    print(f\"Preprocessing input data from {input_path}...\")\\n'\n",
       "  '    time.sleep(1)'),\n",
       " ('FuncDetails(name=train,args=input_path,model_path,has_return=False):\\n'\n",
       "  'def train(input_path: str, model_path: str):\\n'\n",
       "  '    \"\"\"Train the model\"\"\"\\n'\n",
       "  '    import time\\n'\n",
       "  '\\n'\n",
       "  '    print(f\"Training {model_path} on {input_path}...\")\\n'\n",
       "  '    time.sleep(1)'),\n",
       " ('FuncDetails(name=last,args=,has_return=True):\\n'\n",
       "  'def last():\\n'\n",
       "  '    \"\"\"\\n'\n",
       "  '    Clean up and close connections\"\"\"\\n'\n",
       "  '    one = {\"one\": 1}\\n'\n",
       "  '    return one')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def _convert_return_stmt(numbered_step):\n",
    "    number, step = numbered_step\n",
    "    step[\"return_stmt\"] = \"\" if not step[\"return_stmt\"] else step[\"return_stmt\"]\n",
    "    return number, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_dag(test_module: Path):\n",
    "    steps = extract_steps(test_module)\n",
    "\n",
    "    node_ids = list(range(len(steps)))\n",
    "    numbered_steps = zip(node_ids, [asdict(step) for step in steps])\n",
    "\n",
    "    dag = nx.Graph()\n",
    "    dag.add_nodes_from([_convert_return_stmt(s) for s in numbered_steps])\n",
    "    dag.add_edges_from(list(zip(node_ids, node_ids[1:])))\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = extract_dag(test_module)\n",
    "assert [(0, 1), (1, 2), (2, 3)] == list(dag.edges)\n",
    "assert [0, 1, 2, 3] == list(dag.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO fix graph exports - seems to be quite dependent on entworkx version.\n",
    "# nx.write_graphml_lxml(\n",
    "#   dag, os.path.join(Path(\".\").resolve(), \"test\", \"test_dag.graphml\")\n",
    "# )\n",
    "# nx.write_gml(dag, os.path.join(Path(\".\").resolve(), \"test\", \"test_dag.gml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "sciflow (sciflow/3)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:368653567616:image-version/sciflow/3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
