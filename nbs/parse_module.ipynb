{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: parse_module.html\n",
    "title: Write out Test Data\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp parse_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from nbdev.export import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_module_only(package_module_name):\n",
    "    module_name = package_module_name\n",
    "    if \".\" in module_name:\n",
    "        package_name, module_name = module_name.split(\".\")\n",
    "    return module_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_module_name = \"test.module\"\n",
    "module_name = \"module\"\n",
    "path_sep_module_name = module_name.replace(\".\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"module\" == extract_module_only(module_name)\n",
    "assert \"module\" == extract_module_only(pkg_module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_step_code(\n",
    "    module_path: Path,\n",
    "    export_comments=(\"#|export\", \"#|exporti\", \"#|exports\"),\n",
    "    remove_comment_lines=True,\n",
    "):\n",
    "    with open(module_path, \"r\") as module_file:\n",
    "        lines = module_file.readlines()\n",
    "    lines = pd.Series(lines)\n",
    "    step_code = {}\n",
    "    active_step = None\n",
    "    for l in lines.tolist():\n",
    "        trimmed_line = l.lower().replace(\" \", \"\")\n",
    "        if trimmed_line.startswith(\"#|export_step\"):\n",
    "            active_step = trimmed_line.split(\"#|export_step\")[1].strip()\n",
    "        elif trimmed_line.startswith(export_comments):\n",
    "            active_step = None\n",
    "        if l.startswith(\"#\") and remove_comment_lines:\n",
    "            continue\n",
    "        if active_step:\n",
    "            if not active_step in step_code:\n",
    "                step_code[active_step] = []\n",
    "            step_code[active_step].append(l)\n",
    "    for key in step_code.keys():\n",
    "        step_code[key] = \"\".join(step_code[key])\n",
    "    return step_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_module = os.path.join(get_config().path(\"lib_path\"), \"test\", \"test_multistep.py\")\n",
    "step_code = extract_step_code(test_module)\n",
    "step_names = step_code.keys()\n",
    "assert [\"first\", \"preprocess\", \"fit\", \"evaluate\"] == list(step_names)\n",
    "assert all(\n",
    "    [\n",
    "        len([i for i in range(len(sc)) if sc.startswith(\"def\", i)]) == 1\n",
    "        for sc in step_code.values()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m step_code \u001b[38;5;241m=\u001b[39m extract_step_code(test_module)\n\u001b[1;32m      3\u001b[0m step_names \u001b[38;5;241m=\u001b[39m step_code\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m(step_names)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m step_code[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m extract_step_code(test_module, remove_comment_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_module = os.path.join(get_config().path(\"lib_path\"), \"test\", \"test_export.py\")\n",
    "step_code = extract_step_code(test_module)\n",
    "step_names = step_code.keys()\n",
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == list(step_names)\n",
    "assert not step_code[\"first\"].startswith(\"#\")\n",
    "assert extract_step_code(test_module, remove_comment_lines=False)[\"first\"].startswith(\n",
    "    \"#\"\n",
    ")\n",
    "assert all(\n",
    "    [\n",
    "        len([i for i in range(len(sc)) if sc.startswith(\"def\", i)]) == 1\n",
    "        for sc in step_code.values()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FuncLister(ast.NodeVisitor):\n",
    "    has_return = False\n",
    "\n",
    "    def visit_Return(self, node):\n",
    "        self.has_return = True\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.name = node.name\n",
    "        self.docstring = ast.get_docstring(node)\n",
    "        self.args = node.args.args\n",
    "        self.arg_names = [a.arg for a in node.args.args]\n",
    "        self.generic_visit(node)\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, width=120, compact=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FuncDetails:\n",
    "    name: str\n",
    "    docstring: str\n",
    "    args: str\n",
    "    has_return: bool\n",
    "    return_stmt: str\n",
    "    code: str\n",
    "\n",
    "    def __repr__(self):\n",
    "        return pp.pformat(\n",
    "            f\"FuncDetails(name={self.name},args={self.args},has_return={self.has_return}):\\n{self.code.strip()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_func = \"\"\"\n",
    "def some_func():\n",
    "    print 1\n",
    "\"\"\"\n",
    "assert (\n",
    "    FuncDetails(\"a\", None, \"an_arg\", True, \"return True\", some_func).__repr__()\n",
    "    == \"'FuncDetails(name=a,args=an_arg,has_return=True):\\\\ndef some_func():\\\\n    print 1'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_return_stmt(func_name, code):\n",
    "    return_stmt = [\n",
    "        l.strip().split(\"return\")[1].strip()\n",
    "        for l in code.splitlines()\n",
    "        if l.strip().startswith(\"return\")\n",
    "    ]\n",
    "    if len(return_stmt) == 0:\n",
    "        return\n",
    "    return_stmt = return_stmt[0]\n",
    "    is_named_variable = bool(re.search(\"^[a-zA-Z]+[a-zA-Z0-9_]*$\", return_stmt))\n",
    "    if not is_named_variable:\n",
    "        raise NotImplementedError(\n",
    "            f\"Inline return statements are not supported. Assign the return value of {func_name} to a variable before returning.\"\n",
    "        )\n",
    "    return return_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_return = \"\"\"\n",
    "def preprocess(conn, model_level, min_date, traffic_percent):\n",
    "    data = get_utterances(conn, model_level, min_date, traffic_percent)\n",
    "    button_filter = get_button_responses_filter(conn)\n",
    "    user_texts = data[~data.Utterance.isin(button_filter)].copy()\n",
    "    documents = {\"some_field\": user_texts.Utterance.tolist()}\n",
    "    return documents\n",
    "\"\"\"\n",
    "\n",
    "multiple_key_return = \"\"\"\n",
    "def evaluate(model):\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "\n",
    "    topic_contains_non_empty_words = all([len(tw) > 0 for tw in topic_words])\n",
    "    word_scores_in_range = word_scores.min() >= 0.0 and word_scores.max() <= 1.0\n",
    "    as_many_items_as_topics = (\n",
    "        model.get_num_topics() == len(topic_words) == word_scores.shape[0]\n",
    "    )\n",
    "    word_summaries = (\n",
    "        topic_contains_non_empty_words\n",
    "        and word_scores_in_range\n",
    "        and as_many_items_as_topics\n",
    "    )\n",
    "    # You can add artifacts in a step that will be saved to block storage. Add the paths to the file on the local filesystem\n",
    "    # and the artifact will be uploaded to remote storage.\n",
    "    sample_df = pd.DataFrame(\n",
    "        {\"a\": model.get_topic_sizes()[0], \"b\": model.get_topic_sizes()[1]}\n",
    "    )\n",
    "    sample_df.to_csv(\"/tmp/dataframe_artifact.csv\", index=False)\n",
    "    artifacts = [\"/tmp/dataframe_artifact.csv\"]\n",
    "    # You can add step metrics too this time just add a list of 3-tuples where tuple order = (name, value, step)\n",
    "    metrics = [(\"mae\", 100, 0), (\"mae\", 67, 1), (\"mae\", 32, 2)]\n",
    "    results = {\n",
    "        \"word_summaries\": word_summaries,\n",
    "        \"artifacts\": artifacts,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "    return results\n",
    "\"\"\"\n",
    "unnamed_return = \"\"\"\n",
    "def fit(documents, workers=workers, speed=\"fast-learn\"):\n",
    "    return {Top2Vec(documents, workers=workers, speed=speed)}\n",
    "\"\"\"\n",
    "\n",
    "number_return = \"\"\"\n",
    "def fit(documents, workers=workers, speed=\"fast-learn\"):\n",
    "    return 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_code_block = \"\"\"\n",
    "def train(input_path: Path, model_path: Path):\n",
    "    \\\"\"\"Function docs\\\"\"\"\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    print(f'Training {model_path} on {input_path}...')\n",
    "    time.sleep(1)\n",
    "\"\"\"\n",
    "\n",
    "invalid_code_block = \"\"\"\n",
    "def train(input_path: Path, model_path: Path):\n",
    "    import time\n",
    "    import pandas as pd\n",
    "    print(f'Training {model_path} on {input_path}...')\n",
    "    time.slurp(1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extract_return_stmt(\"train\", named_return) == \"documents\"\n",
    "assert extract_return_stmt(\"train\", valid_code_block) is None\n",
    "try:\n",
    "    extract_return_stmt(\"train\", number_return)\n",
    "except NotImplementedError as e:\n",
    "    assert e is not None\n",
    "try:\n",
    "    extract_return_stmt(\"train\", unnamed_return)\n",
    "except NotImplementedError as e:\n",
    "    assert e is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def parse_step(step_code: str):\n",
    "    tree = ast.parse(step_code)\n",
    "    lister = FuncLister()\n",
    "    lister.visit(tree)\n",
    "    if \"name\" not in lister.__dict__:\n",
    "        raise (\n",
    "            ValueError(\"Step must have a single valid function; check step definition\")\n",
    "        )\n",
    "    return FuncDetails(\n",
    "        lister.name,\n",
    "        lister.docstring,\n",
    "        \",\".join(lister.arg_names),\n",
    "        lister.has_return,\n",
    "        extract_return_stmt(lister.name, step_code),\n",
    "        step_code,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_return_var_names(step):\n",
    "    results_index = step.code.find(f\"{step.return_stmt} =\")\n",
    "    if results_index == -1:\n",
    "        return []\n",
    "\n",
    "    keys = []\n",
    "    for l in step.code[results_index:].split(\"\\n\"):\n",
    "        if l.strip().find(\":\") > -1:\n",
    "            key_prefix = l.split(\":\")[0]\n",
    "            key = key_prefix[key_prefix.find(\"{\") + 1 :]\n",
    "            keys.append(key.strip(' \",'))\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"some_field\"] == extract_return_var_names(parse_step(named_return))\n",
    "assert [\"word_summaries\", \"artifacts\", \"metrics\"] == extract_return_var_names(\n",
    "    parse_step(multiple_key_return)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"documents\" == parse_step(named_return).return_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dets = parse_step(valid_code_block)\n",
    "assert func_dets.name == \"train\"\n",
    "assert func_dets.args == \",\".join([\"input_path\", \"model_path\"])\n",
    "assert not func_dets.has_return\n",
    "assert type(func_dets.code) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_steps(module_path: Path):\n",
    "    step_code = extract_step_code(module_path)\n",
    "    steps = [parse_step(step_code[k]) for k in step_code.keys()]\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _convert_return_stmt(numbered_step):\n",
    "    number, step = numbered_step\n",
    "    step[\"return_stmt\"] = \"\" if not step[\"return_stmt\"] else step[\"return_stmt\"]\n",
    "    return number, step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
