{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciflow ðŸ”¬\n",
    "\n",
    "**This library bridges the gap between research and production for Data Science.** This library takes a different approach to achieve this than many others do.. the interactive notebook is the primary driver of exploration. Exploration driven development is a different paradigm to most software engineering exercises. `sciflow` mixes the strengths of the notebook environment: flexibility, access to data and constant feedback with the strengths of production-like workflows: resilience and dedicated compute.\n",
    "\n",
    "A popular approach to productionising research code in notebooks is to lift the workflow from notebooks to a python modules via a manual rewrite process. Sometimes one person will have the skills and ability to perform this task but mostly it will be a collaborative effort to understand and rewrite the code for more robust production ready purpose. \n",
    "\n",
    "As a team you can get to be good at this process but there is always a lag between the exploration being performed now and the ability to test that out in live environments. If the person writing the experimental approach was able, without switching hats to \"development mode\" to see their exploration validated safely by production users then this should be transformative for the impact of Data Science in your organisation. \n",
    "\n",
    "The discipline of Software Development offers many approaches to ensuring code is of high quality with consistent style and testable assertions on known data. Data Science and Machine Learning introduce new Software Development challenges that are not as well explored by the community. In Data Science behaviour is a more fundamental unit for testing than logic for instance so tests on real user data will show your model works as expected syntethic data is unlikely to achieve the same.\n",
    "\n",
    "Modern notebook environment have a common advantage in practice over many local development environments and that is that Data Scientists can write code against real data with all the quirks and anomolaies and underlying behaviour that they are actually trying to develop a solution against. We start by assuming only that there are high levels of uncertainty and that the code needs not only to work but to be well conditioned to real data. \n",
    "\n",
    "# Purpose\n",
    "\n",
    "Scientists can benefit from:\n",
    "* Trying more ideas\n",
    "* Easier collaboration\n",
    "* Workflow portability\n",
    "* Tracked Experiments\n",
    "\n",
    "Data Science teams can benefit from:\n",
    "* Shorter production lead times\n",
    "* Easier collaboration between anybody involved in turning research into production\n",
    "* Knowing what is important from a deployment perspective within a notebook\n",
    "* Knowing that research code still has a quality standard\n",
    "\n",
    "Sciflow ðŸ”¬ makes it easier to validate your research in production.\n",
    "\n",
    "*Note: Sciflow is built on top of the excellent `nbdev` library (by fastai) and wouldn't be possible without the creation of the literate programming environment made possible by that library.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Consolidation\n",
    "\n",
    "Progressive consolidation is a development idealogy for exploratory programming. You start by writing code which optimises for speed of exploration. You will mostly have scripted code cells with little or no functions and minimal code re-use. As time goes by you will know which parts of your notebook are important and you consolidate those to a higher level of quality. \n",
    "\n",
    "In `sciflow` we simplify quality to mean functions and tests for those functions. `nbdev` lets us mark functions and code that is important for the production element of our work using the `# export` directive. \n",
    "\n",
    "See https://nbdev.fast.ai/tutorial.html to get started using nbdev."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "\n",
    "If any functions are important and you want to bring them with you to your production experiment then export them using nbdev."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components\n",
    "\n",
    "* Ensure notebooks meet style standards (`nbqa`)\n",
    "* Create workflow from notebook steps (`ndbev`)\n",
    "* Experiment tracking (`sacred/incense`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "Steps are functions which can be executed independently. Structuring your code into steps brings many benefits:\n",
    "\n",
    "* Save Time:\n",
    "    * Checkpointing: can skip having to run expensive steps again\n",
    "    * Re-use: write a step once and use in many different workflows\n",
    "    \n",
    "* Easier to debug\n",
    "    * You can narrow down where the problem is happening quicker and can use print statements or a debugger within the fewlines of a functino rather than a longer script.\n",
    "    \n",
    "* Portability\n",
    "    * Steps can be run on different machines; potentially in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows\n",
    "\n",
    "A flow is short for workflow; they help you structure your work into something can be executed from start to finish. Structuring your work into flows has the following benefits:\n",
    "\n",
    "* Ordered execution: anyone can run your workflow because the order is defined.\n",
    "* Portability: writing your research as a flow helps to draw out dependencies on libraries or anything that can run in your environment but not elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "* `pip install sciflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands\n",
    "       \n",
    "* nbdev_diff_nbs                   \n",
    "* nbdev_fix_merge          \n",
    "* nbdev_test_nbs  \n",
    "* nbdev_clean_nbs                                  \n",
    "* nbdev_new     \n",
    "* sciflow_tidy\n",
    "* sciflow_build_lib\n",
    "* sciflow_prepare\n",
    "* sciflow_build\n",
    "* sciflow_generate\n",
    "* sciflow_check_flows\n",
    "* sciflow_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sciflow]",
   "language": "python",
   "name": "conda-env-sciflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
