{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp to_metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "from fastcore.script import Param, call_parse\n",
    "from nbdev.export import find_default_export, get_config, nbglob, read_nb\n",
    "\n",
    "from sciflow.data_handler import extract_param_meta\n",
    "from sciflow.params import params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_module_only, extract_steps\n",
    "from sciflow.utils import get_flow_path, indent_multiline, prepare_env, titleize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciflow Notebook to MetaFlow Flow\n",
    "\n",
    "> Converts from a `sciflow` format notebook to a `metaflow` flow. \n",
    "\n",
    "Supported features:\n",
    "\n",
    "* Linear/sequential DAGs\n",
    "* Simple `Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_export.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def rename_steps_for_metaflow(steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        if i == 0:\n",
    "            step.name = \"start\"\n",
    "        elif i == len(steps) - 1:\n",
    "            step.name = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_steps = extract_steps(os.path.join(get_config().path(\"lib_path\"), f\"_nbdev.py\"))\n",
    "assert len(no_steps) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]\n",
    "rename_steps_for_metaflow(steps)\n",
    "assert [\"start\", \"preprocess\", \"train\", \"end\"] == [step.name for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_tracking.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def nb_to_metaflow(nb_path: Path, flow_path: Path, silent=True, track_experiment=True):\n",
    "    nb = read_nb(nb_path)\n",
    "    lib_name = get_config().get(\"lib_name\")\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    if not module_name:\n",
    "        return\n",
    "    module_name = module_name\n",
    "    path_sep_module_name = module_name.replace(\".\", \"/\")\n",
    "    nb_name = os.path.basename(nb_path)\n",
    "    exported_module = os.path.join(\n",
    "        get_config().path(\"lib_path\"), f\"{path_sep_module_name}.py\"\n",
    "    )\n",
    "    steps = extract_steps(exported_module)\n",
    "    if len(steps) == 0:\n",
    "        return\n",
    "    orig_step_names = [step.name for step in steps]\n",
    "    if len(steps) == 1:\n",
    "        steps.append(FuncDetails(\"end\", None, None, False, \"\", \"pass\"))\n",
    "    params = params_as_dict(nb_path)\n",
    "    if len(params) == 0:\n",
    "        print(f\"No params cell found for: {os.path.basename(nb_path)}\")\n",
    "    flow_class_name = f\"{titleize(extract_module_only(module_name))}Flow\"\n",
    "    rename_steps_for_metaflow(steps)\n",
    "    write_module_to_file(\n",
    "        flow_path,\n",
    "        flow_class_name,\n",
    "        lib_name,\n",
    "        module_name,\n",
    "        orig_step_names,\n",
    "        steps,\n",
    "        params,\n",
    "        track_experiment,\n",
    "    )\n",
    "    if track_experiment:\n",
    "        write_cli_wrapper(\n",
    "            flow_path, extract_module_only(module_name), [s.name for s in steps]\n",
    "        )\n",
    "    if not silent:\n",
    "        print(\n",
    "            f\"Converted {nb_name} to {flow_class_name} in: {os.path.basename(flow_path)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_module_to_file(\n",
    "    flow_path: Path,\n",
    "    flow_class_name: str,\n",
    "    lib_name: str,\n",
    "    module_name: str,\n",
    "    orig_step_names: Iterable[str],\n",
    "    steps: Iterable[FuncDetails],\n",
    "    params: dict,\n",
    "    track_experiment: bool,\n",
    "):\n",
    "    if not os.path.exists(flow_path.parent):\n",
    "        os.mkdir(flow_path.parent)\n",
    "    fq_module_name = f\"{lib_name}.{module_name}\"\n",
    "    param_meta = extract_param_meta(fq_module_name, params)\n",
    "    with open(flow_path, \"w\") as flow_file:\n",
    "        flow_file.write(\"#!/usr/bin/env python\\n\")\n",
    "        flow_file.write(\"# coding=utf-8\\n\")\n",
    "        flow_file.write(\"# SCIFLOW GENERATED FILE - EDIT COMPANION NOTEBOOK\\n\")\n",
    "        has_mf_param = any((p.has_metaflow_param for p in param_meta.values()))\n",
    "        has_json_param = any((p.is_json_type for p in param_meta.values()))\n",
    "        mf_params_import = \"from metaflow import FlowSpec, step, current\"\n",
    "        if has_mf_param or track_experiment:\n",
    "            mf_params_import += \", Parameter\"\n",
    "        if has_json_param:\n",
    "            mf_params_import += \", JSONType\"\n",
    "            flow_file.write(\"import json\\n\")\n",
    "        flow_file.write(mf_params_import + \"\\n\")\n",
    "        flow_file.write(f\"from {fq_module_name} import {', '.join(orig_step_names)}\\n\")\n",
    "        if len(params) > 0:\n",
    "            flow_file.write(\n",
    "                f\"from {fq_module_name} import {', '.join(params.keys())}\\n\"\n",
    "            )\n",
    "        if track_experiment:\n",
    "            flow_file.write(f\"from sciflow.experiment.tracking import StepTracker\\n\")\n",
    "            flow_file.write(f\"import sys\\n\")\n",
    "            flow_file.write(f\"import tempfile\\n\")\n",
    "\n",
    "        flow_file.write(f\"\\n\\nclass {flow_class_name}(FlowSpec):\\n\")\n",
    "        ind = \"    \"\n",
    "        write_params(flow_file, param_meta, ind, track_experiment)\n",
    "        flow_file.write(\"\\n\")\n",
    "        write_steps(\n",
    "            flow_file,\n",
    "            steps,\n",
    "            orig_step_names,\n",
    "            param_meta,\n",
    "            ind,\n",
    "            track_experiment,\n",
    "        )\n",
    "        flow_file.write(\"\\n\")\n",
    "\n",
    "        flow_file.write('if __name__ == \"__main__\":\\n')\n",
    "        flow_file.write(f\"{ind}{flow_class_name}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_params(flow_file, param_meta, ind, track_experiment):\n",
    "    for param in param_meta.keys():\n",
    "        if param_meta[param].is_scalar:\n",
    "            flow_file.write(f\"{ind}{param} = Parameter('{param}', default={param})\\n\")\n",
    "        elif param_meta[param].is_json_type:\n",
    "            flow_file.write(\n",
    "                f\"{ind}{param} = Parameter('{param}', default=json.dumps({param}), type=JSONType)\\n\"\n",
    "            )\n",
    "        elif param_meta[param].instance_type == PosixPath:\n",
    "            flow_file.write(\n",
    "                f\"{ind}{param} = Parameter('{param}', default=str({param}))\\n\"\n",
    "            )\n",
    "    if track_experiment:\n",
    "        flow_file.write(f\"{ind}bucket_name = Parameter('bucket_name', required=True)\\n\")\n",
    "        flow_file.write(\n",
    "            f\"{ind}flow_base_key = Parameter('flow_base_key', required=True)\\n\"\n",
    "        )\n",
    "        flow_file.write(f\"{ind}flow_run_id = Parameter('flow_run_id', required=True)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = os.path.join(Path(\".\").resolve(), \"test\", \"test_data_handling.ipynb\")\n",
    "params = params_as_dict(nb_path)\n",
    "param_meta = extract_param_meta(\"sciflow.test.test_data_handling\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any((p.has_metaflow_param for p in param_meta.values()))\n",
    "assert any((p.is_json_type for p in param_meta.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def format_arg(arg, param_meta):\n",
    "    if arg in param_meta and not param_meta[arg].has_metaflow_param:\n",
    "        result = arg\n",
    "    else:\n",
    "        result = \"self.\" + arg\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_steps(flow_file, steps, orig_step_names, param_meta, ind, track_experiment):\n",
    "    for i, step in enumerate(steps):\n",
    "        if track_experiment:\n",
    "            # Check for padded step\n",
    "            if i < len(orig_step_names):\n",
    "                flow_step_args = \"\"\n",
    "                if len(step.args) > 0:\n",
    "                    flow_step_args = \", \".join(\n",
    "                        [format_arg(a, param_meta) for a in step.args.split(\",\")]\n",
    "                    )\n",
    "\n",
    "                step_func_call_text = f\"{orig_step_names[i]}({flow_step_args})\"\n",
    "\n",
    "                write_track_internal_helper(\n",
    "                    flow_file,\n",
    "                    ind,\n",
    "                    param_meta,\n",
    "                    steps,\n",
    "                    orig_step_names[i],\n",
    "                    step_func_call_text.replace(\"self.tracker\", \"tracker\"),\n",
    "                    i,\n",
    "                )\n",
    "        else:\n",
    "            flow_file.write(f\"{ind}@step\\n\")\n",
    "            flow_file.write(f\"{ind}def {step.name}(self):\\n\")\n",
    "            if step.docstring:\n",
    "                flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "\n",
    "            if i < len(orig_step_names):\n",
    "                flow_step_args = \"\"\n",
    "                if len(step.args) > 0:\n",
    "                    flow_step_args = \", \".join(\n",
    "                        [format_arg(a, param_meta) for a in step.args.split(\",\")]\n",
    "                    )\n",
    "                if not step.has_return:\n",
    "                    flow_file.write(\n",
    "                        f\"{ind}{ind}{orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    if step.return_stmt in param_meta:\n",
    "                        raise ValueError(\n",
    "                            f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "                        )\n",
    "                    flow_file.write(\n",
    "                        f\"{ind}{ind}results = {orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                    )\n",
    "                    write_track_capture(flow_file, ind, 2)\n",
    "            else:\n",
    "                flow_file.write(f\"{ind}{ind}pass\\n\")\n",
    "                flow_file.write(\"\\n\")\n",
    "            if i < len(steps) - 1:\n",
    "                next_step = steps[i + 1].name\n",
    "                flow_file.write(f\"{ind}{ind}self.next(self.{next_step})\\n\")\n",
    "            flow_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_capture(flow_file, ind, num_indents):\n",
    "    base_ind = \"\".join(np.repeat(ind, num_indents))\n",
    "    flow_file.write(f\"{base_ind}for key in results.keys():\\n\")\n",
    "    flow_file.write(f\"{base_ind}{ind}if key in self.__dict__:\\n\")\n",
    "    flow_file.write(\n",
    "        f\"{base_ind}{ind}{ind}self.__dict__[key] = self.__dict__[key] + results[key]\\n\"\n",
    "    )\n",
    "    flow_file.write(f\"{base_ind}{ind}else:\\n\")\n",
    "    flow_file.write(f\"{base_ind}{ind}{ind}self.__dict__[key] = results[key]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_internal_helper(\n",
    "    flow_file, ind, param_meta, steps, orig_step_name, step_func_call_text, i\n",
    "):\n",
    "    step = steps[i]\n",
    "    flow_file.write(f\"{ind}def _{step.name}(self):\\n\")\n",
    "    if step.docstring:\n",
    "        flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "    flow_file.write(f\"{ind}{ind}tracker = None\\n\")\n",
    "    flow_file.write(f\"{ind}{ind}try:\\n\")\n",
    "    flow_file.write(\n",
    "        f'{ind}{ind}{ind}tracker = StepTracker(self.bucket_name, self.flow_base_key, self.flow_run_id, \"{orig_step_name}\")\\n'\n",
    "    )\n",
    "    flow_file.write(f\"{ind}{ind}{ind}with tempfile.TemporaryDirectory() as temp_dir:\\n\")\n",
    "    flow_file.write(\n",
    "        f\"{ind}{ind}{ind}{ind}with tracker.capture_out() as tracker._output_file:\\n\"\n",
    "    )\n",
    "    flow_file.write(f\"{ind}{ind}{ind}{ind}{ind}tracker.start_heartbeat(10.0)\\n\")\n",
    "\n",
    "    if not step.has_return:\n",
    "        flow_file.write(f\"{ind}{ind}{ind}{ind}{ind}{step_func_call_text}\\n\")\n",
    "    else:\n",
    "        if step.return_stmt in param_meta:\n",
    "            raise ValueError(\n",
    "                f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "            )\n",
    "        flow_file.write(f\"{ind}{ind}{ind}{ind}{ind}results = {step_func_call_text}\\n\")\n",
    "        write_track_capture(flow_file, ind, 5)\n",
    "\n",
    "    flow_file.write(f\"{ind}{ind}{ind}{ind}{ind}tracker.completed()\\n\")\n",
    "    flow_file.write(f\"{ind}{ind}except BaseException:\\n\")\n",
    "    flow_file.write(f\"{ind}{ind}{ind}if tracker:\\n\")\n",
    "    flow_file.write(\n",
    "        f\"{ind}{ind}{ind}{ind}exc_type, exc_value, trace = sys.exc_info()\\n\"\n",
    "    )\n",
    "    flow_file.write(\n",
    "        f'{ind}{ind}{ind}{ind}except_info = {{\"exc_type\": exc_type, \"exc_value\": exc_value, \"trace\": trace}}\\n'\n",
    "    )\n",
    "    flow_file.write(\n",
    "        f'{ind}{ind}{ind}{ind}tracker.completed(status=\"FAILED\", except_info=except_info)\\n'\n",
    "    )\n",
    "    flow_file.write(f\"{ind}{ind}{ind}raise\\n\\n\")\n",
    "    flow_file.write(f\"{ind}@step\\n\")\n",
    "    flow_file.write(f\"{ind}def {step.name}(self):\\n\")\n",
    "    flow_file.write(f\"{ind}{ind}self._{step.name}()\\n\")\n",
    "    if i < len(steps) - 1:\n",
    "        next_step = steps[i + 1].name\n",
    "        flow_file.write(f\"{ind}{ind}self.next(self.{next_step})\\n\")\n",
    "    flow_file.write(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaflow CLI Wrapper\n",
    "\n",
    "Metaflow does  not currently allow the main function to be wrapper inside a flow module. Resorting to using another module CLI to get the right behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_cli_wrapper(flow_path, flow_base_key, steps):\n",
    "    wrapper_body = f\"\"\"from metaflow import FlowSpec, step, current\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sciflow.experiment.tracking import FlowTracker, StepTracker\n",
    "from sciflow.run_flow import run_shell_cmd\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wrapped_module = \"{flow_path.stem}\"\n",
    "    if len(sys.argv) == 1:\n",
    "        cmd = f\"python _{flow_path.stem} show\"\n",
    "        pipe, output = run_shell_cmd(cmd)\n",
    "        print(output)\n",
    "    else:\n",
    "        if \"show\" in sys.argv or \"help\" in sys.argv[1]:\n",
    "            full_cmd = \" \".join(sys.argv)\n",
    "            cmd = f\"python {{full_cmd.replace(sys.argv[0], wrapped_module)}}\"\n",
    "            pipe, output = run_shell_cmd(cmd)\n",
    "            print(output)\n",
    "        elif \"run\" in sys.argv[1]: \n",
    "            bucket_name = os.environ['SCIFLOW_BUCKET']\n",
    "            run_timestamp = datetime.today().__str__().replace(':', '-').replace('.', '-').replace(' ', '-')[:-3]\n",
    "            flow_base_key = \"{flow_base_key}\"\n",
    "            flow_run_id = f\"flow-{{run_timestamp}}\"\n",
    "            steps = {steps}\n",
    "        \n",
    "            flow_tracker = FlowTracker(os.environ['SCIFLOW_BUCKET'], flow_base_key, flow_run_id, steps)\n",
    "            flow_tracker.start()\n",
    "            \n",
    "            try:\n",
    "                sys.argv[1] = \"--no-pylint run\"\n",
    "                full_cmd = \" \".join(sys.argv)\n",
    "                full_cmd += f\" --bucket_name {{bucket_name}} --flow_base_key {{flow_base_key}} --flow_run_id {{flow_run_id}}\"\n",
    "                cmd = f\"python {{full_cmd.replace(sys.argv[0], wrapped_module)}}\"\n",
    "                pipe, output = run_shell_cmd(cmd)\n",
    "                print(output)\n",
    "            except (KeyboardInterrupt):\n",
    "                flow_tracker.interrupted()\n",
    "                print(f\"Flow interrupted by user: {{flow_run_id}}\")\n",
    "            except BaseException:\n",
    "                exc_type, exc_value, trace = sys.exc_info()\n",
    "                except_info = {{\"exc_type\": exc_type, \"exc_value\": exc_value, \"trace\": trace}}\n",
    "                flow_tracker.failed(except_info)\n",
    "                print(f\"Flow failed: {{flow_run_id}}\")\n",
    "\n",
    "            flow_tracker.completed()\"\"\"\n",
    "    shutil.copyfile(\n",
    "        flow_path, str(flow_path).replace(flow_base_key, f\"_sciflow_{flow_base_key}\")\n",
    "    )\n",
    "    with open(flow_path, \"w\") as wrapper_file:\n",
    "        wrapper_file.write(wrapper_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Flow Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(\n",
    "    Path(\".\").resolve(), \"test\", \"flows\", \"metaflow\", f\"test_data_handling.py\"\n",
    ") == get_flow_path(Path(Path(\".\").resolve(), \"test\", f\"test_data_handling.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(nb_path, get_flow_path(nb_path), silent=False, track_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\n",
    "    Path(\n",
    "        Path(\".\").resolve(),\n",
    "        \"test\",\n",
    "        \"test_multistep.ipynb\",\n",
    "    ),\n",
    "    get_flow_path(Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\")),\n",
    "    silent=False,\n",
    "    track_experiment=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore notebooks without Sciflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\"packaging.ipynb\", get_flow_path(\"packaging.ipynb\"), silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def generate_flows(config=None, track_experiment=True):\n",
    "    nb_paths = nbglob(recursive=True)\n",
    "    for nb_path in nb_paths:\n",
    "        nb_to_metaflow(\n",
    "            nb_path,\n",
    "            get_flow_path(nb_path, config=config),\n",
    "            track_experiment=track_experiment,\n",
    "            silent=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_flows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_flows(track_experiment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_metaflow(track: Param(\"Track flows as experiments\", type=bool)):\n",
    "    print(f\"Converting flows to metaflow (experiment tracking = {track})\")\n",
    "    generate_flows(get_config(), track)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciflow (sciflow/3)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:368653567616:image-version/sciflow/3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
