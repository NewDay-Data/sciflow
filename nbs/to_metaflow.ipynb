{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp to_metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterable\n",
    "\n",
    "from fastcore.script import Param, call_parse\n",
    "from nbdev.export import find_default_export, get_config, nbglob, read_nb\n",
    "\n",
    "from sciflow.data_handler import extract_param_meta\n",
    "from sciflow.params import params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_module_only, extract_steps\n",
    "from sciflow.utils import get_flow_path, indent_multiline, prepare_env, titleize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciflow Notebook to MetaFlow Flow\n",
    "\n",
    "> Converts from a `sciflow` format notebook to a `metaflow` flow. \n",
    "\n",
    "Supported features:\n",
    "\n",
    "* Linear/sequential DAGs\n",
    "* Simple `Parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_export.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def rename_steps_for_metaflow(steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        if i == 0:\n",
    "            step.name = \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_steps = extract_steps(os.path.join(get_config().path(\"lib_path\"), f\"_nbdev.py\"))\n",
    "assert len(no_steps) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]\n",
    "rename_steps_for_metaflow(steps)\n",
    "assert [\"start\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_multistep.ipynb\"))\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def nb_to_metaflow(nb_path: Path, flow_path: Path, silent=True, track_experiment=True):\n",
    "    nb = read_nb(nb_path)\n",
    "    lib_name = get_config().get(\"lib_name\")\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    if not module_name:\n",
    "        return\n",
    "    module_name = module_name\n",
    "    path_sep_module_name = module_name.replace(\".\", \"/\")\n",
    "    nb_name = os.path.basename(nb_path)\n",
    "    exported_module = os.path.join(\n",
    "        get_config().path(\"lib_path\"), f\"{path_sep_module_name}.py\"\n",
    "    )\n",
    "    steps = extract_steps(exported_module)\n",
    "    if len(steps) == 0:\n",
    "        return\n",
    "    orig_step_names = [step.name for step in steps]\n",
    "    if len(steps) == 1:\n",
    "        steps.append(FuncDetails(\"end\", None, None, False, \"\", \"pass\"))\n",
    "    params = params_as_dict(nb_path)\n",
    "    if len(params) == 0:\n",
    "        print(f\"No params cell found for: {os.path.basename(nb_path)}\")\n",
    "    flow_class_name = f\"{titleize(extract_module_only(module_name))}Flow\"\n",
    "    rename_steps_for_metaflow(steps)\n",
    "    write_module_to_file(\n",
    "        flow_path,\n",
    "        flow_class_name,\n",
    "        lib_name,\n",
    "        module_name,\n",
    "        orig_step_names,\n",
    "        steps,\n",
    "        params,\n",
    "        track_experiment,\n",
    "    )\n",
    "    if not silent:\n",
    "        print(\n",
    "            f\"Converted {nb_name} to {flow_class_name} in: {os.path.basename(flow_path)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_module_to_file(\n",
    "    flow_path: Path,\n",
    "    flow_class_name: str,\n",
    "    lib_name: str,\n",
    "    module_name: str,\n",
    "    orig_step_names: Iterable[str],\n",
    "    steps: Iterable[FuncDetails],\n",
    "    params: dict,\n",
    "    track_experiment: bool,\n",
    "):\n",
    "    if not os.path.exists(flow_path.parent):\n",
    "        os.mkdir(flow_path.parent)\n",
    "    fq_module_name = f\"{lib_name}.{module_name}\"\n",
    "    param_meta = extract_param_meta(fq_module_name, params)\n",
    "    with open(flow_path, \"w\") as flow_file:\n",
    "        flow_file.write(\"#!/usr/bin/env python\\n\")\n",
    "        flow_file.write(\"# coding=utf-8\\n\")\n",
    "        flow_file.write(\"# SCIFLOW GENERATED FILE - EDIT COMPANION NOTEBOOK\\n\")\n",
    "        has_mf_param = any((p.has_metaflow_param for p in param_meta.values()))\n",
    "        has_json_param = any((p.is_json_type for p in param_meta.values()))\n",
    "        mf_params_import = \"from metaflow import FlowSpec, step, current\"\n",
    "        if has_mf_param:\n",
    "            mf_params_import += \", Parameter\"\n",
    "        if has_json_param:\n",
    "            mf_params_import += \", JSONType\"\n",
    "            flow_file.write(\"import json\\n\")\n",
    "        flow_file.write(mf_params_import + \"\\n\")\n",
    "        flow_file.write(f\"from {fq_module_name} import {', '.join(orig_step_names)}\\n\")\n",
    "        if len(params) > 0:\n",
    "            flow_file.write(\n",
    "                f\"from {fq_module_name} import {', '.join(params.keys())}\\n\"\n",
    "            )\n",
    "\n",
    "        if track_experiment:\n",
    "            flow_file.write(\"from sacred import Experiment\\n\")\n",
    "            flow_file.write(\n",
    "                \"from sciflow.experiment.lake_observer import AWSLakeObserver\\n\"\n",
    "            )\n",
    "            flow_file.write(\"import time\")\n",
    "            write_observers(\n",
    "                lib_name,\n",
    "                flow_file,\n",
    "                module_name,\n",
    "                os.environ[\"SCIFLOW_BUCKET\"],\n",
    "                get_config().get(\"lib_name\"),\n",
    "            )\n",
    "\n",
    "        flow_file.write(f\"\\n\\nclass {flow_class_name}(FlowSpec):\\n\")\n",
    "        single_indent = \"    \"\n",
    "        write_params(flow_file, param_meta, single_indent)\n",
    "        if track_experiment:\n",
    "            flow_file.write(f\"{single_indent}artifacts = []\\n\")\n",
    "            flow_file.write(f\"{single_indent}metrics = []\\n\")\n",
    "        flow_file.write(\"\\n\")\n",
    "        write_steps(\n",
    "            flow_file,\n",
    "            steps,\n",
    "            orig_step_names,\n",
    "            param_meta,\n",
    "            single_indent,\n",
    "            track_experiment,\n",
    "        )\n",
    "        write_track_flow(flow_file, track_experiment)\n",
    "        flow_file.write(\"\\n\")\n",
    "\n",
    "        flow_file.write('if __name__ == \"__main__\":\\n')\n",
    "        flow_file.write(f\"{single_indent}{flow_class_name}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_observers(lib_name, flow_file, module_name, bucket_name, project):\n",
    "    experiment_name = extract_module_only(module_name)\n",
    "    sacred_setup = f\"\"\"\n",
    "\n",
    "ex = Experiment(\"{experiment_name}\")\n",
    "# TODO inject observers\n",
    "obs = AWSLakeObserver(project=\"{lib_name}\", experiment_name=\"{experiment_name}\")\n",
    "ex.observers.append(obs)\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    flow_run_id = None\n",
    "    artifacts = []\n",
    "    metrics = []\n",
    "    \"\"\"\n",
    "    flow_file.write(sacred_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_flow(flow_file, track_experiment):\n",
    "    track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        flow_info = {\n",
    "            \"flow_name\": current.flow_name,\n",
    "            \"run_id\": current.run_id,\n",
    "            \"pathspec\": current.pathspec,\n",
    "            \"namespace\": current.namespace,\n",
    "            \"username\": current.username,\n",
    "            \"flow_parameters\": str(current.parameter_names),\n",
    "            \"run_time_mins\": round((time.time() - self.__getattr__('start_time')) / 60.0, 1)\n",
    "        }\n",
    "    \n",
    "        run = ex.run(config_updates={'artifacts': self.__getattr__('artifacts'),\n",
    "                                    'metrics': self.__getattr__('metrics')},\n",
    "                     meta_info = flow_info)\n",
    "        \n",
    "    @ex.main\n",
    "    def track_flow(artifacts, metrics, _run):\n",
    "        for artifact in artifacts:\n",
    "            _run.add_artifact(artifact)\n",
    "        for metric_name, metric_value, step in metrics:\n",
    "            _run.log_scalar(metric_name, metric_value, step)\n",
    "    \"\"\"\n",
    "    if not track_experiment:\n",
    "        track_flow = \"\"\"\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \"\"\"\n",
    "    flow_file.write(track_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  export\n",
    "\n",
    "\n",
    "def write_params(flow_file, param_meta, single_indent):\n",
    "    for param in param_meta.keys():\n",
    "        if param_meta[param].is_scalar:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default={param})\\n\"\n",
    "            )\n",
    "        elif param_meta[param].is_json_type:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=json.dumps({param}), type=JSONType)\\n\"\n",
    "            )\n",
    "        elif param_meta[param].instance_type == PosixPath:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{param} = Parameter('{param}', default=str({param}))\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = os.path.join(Path(\".\").resolve(), \"test\", \"test_data_handling.ipynb\")\n",
    "params = params_as_dict(nb_path)\n",
    "param_meta = extract_param_meta(\"sciflow.test.test_data_handling\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert any((p.has_metaflow_param for p in param_meta.values()))\n",
    "assert any((p.is_json_type for p in param_meta.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def format_arg(arg, param_meta):\n",
    "    if arg in param_meta and not param_meta[arg].has_metaflow_param:\n",
    "        result = arg\n",
    "    else:\n",
    "        result = \"self.\" + arg\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_steps(\n",
    "    flow_file, steps, orig_step_names, param_meta, single_indent, track_experiment\n",
    "):\n",
    "    for i, step in enumerate(steps):\n",
    "        flow_file.write(f\"{single_indent}@step\\n\")\n",
    "        flow_file.write(f\"{single_indent}def {step.name}(self):\\n\")\n",
    "        if step.docstring:\n",
    "            flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "        # Check for padded step\n",
    "        if i < len(orig_step_names):\n",
    "            flow_step_args = \"\"\n",
    "            if len(step.args) > 0:\n",
    "                flow_step_args = \", \".join(\n",
    "                    [format_arg(a, param_meta) for a in step.args.split(\",\")]\n",
    "                )\n",
    "            if not step.has_return:\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}{orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "            else:\n",
    "                if step.return_stmt in param_meta:\n",
    "                    raise ValueError(\n",
    "                        f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "                    )\n",
    "                flow_file.write(\n",
    "                    f\"{single_indent}{single_indent}results = {orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "                write_track_capture(flow_file)\n",
    "        if i == 0 and track_experiment:\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.start_time = time.time()\\n\"\n",
    "            )\n",
    "        if i < len(steps):\n",
    "            next_step = \"end\" if i == len(steps) - 1 else steps[i + 1].name\n",
    "            flow_file.write(\n",
    "                f\"{single_indent}{single_indent}self.next(self.{next_step})\\n\"\n",
    "            )\n",
    "        flow_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_track_capture(flow_file):\n",
    "    flow_file.write(\n",
    "        f\"\"\"\n",
    "        for key in results.keys():\n",
    "            if key in self.__dict__:\n",
    "                self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "            else:\n",
    "                self.__dict__[key] = results[key]\n",
    "\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Flow Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(\n",
    "    Path(\".\").resolve(), \"test\", \"flows\", \"metaflow\", f\"test_data_handling.py\"\n",
    ") == get_flow_path(Path(Path(\".\").resolve(), \"test\", f\"test_data_handling.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(nb_path, get_flow_path(nb_path), silent=False, track_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\n",
    "    Path(\n",
    "        Path(\".\").resolve(),\n",
    "        \"test\",\n",
    "        \"test_multistep.ipynb\",\n",
    "    ),\n",
    "    get_flow_path(Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\")),\n",
    "    silent=False,\n",
    "    track_experiment=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore notebooks without Sciflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\"packaging.ipynb\", get_flow_path(\"packaging.ipynb\"), silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def generate_flows(config=None, track_experiment=True):\n",
    "    nb_paths = nbglob(recursive=True)\n",
    "    for nb_path in nb_paths:\n",
    "        nb_to_metaflow(\n",
    "            nb_path,\n",
    "            get_flow_path(nb_path, config=config),\n",
    "            track_experiment=track_experiment,\n",
    "            silent=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_flows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_flows(track_experiment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_metaflow(track: Param(\"Track flows as sacred experiments\", bool) = True):\n",
    "    generate_flows(get_config(), track)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciflow (sciflow/3)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:368653567616:image-version/sciflow/3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
