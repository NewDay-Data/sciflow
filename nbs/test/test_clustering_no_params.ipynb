{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp test.test_clustering_no_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportn_step:first\n",
    "\n",
    "\n",
    "def something():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Discovery with Top2Vec\n",
    "\n",
    "> top2vec is an unsupervised topic detection algorithm. It finds clusters of similar texts and then groups them into meaningful topics.\n",
    "* Get Topics\n",
    "* Get Words\n",
    "* Get Docs\n",
    "\n",
    "# Look at:\n",
    "\n",
    "* https://github.com/fastai/fastdoc\n",
    "* https://github.com/fastai/fastpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sciflow.utils import odbc_connect, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params\n",
    "\n",
    "> These parameters are managed by papermill execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "traffic_percent = 1\n",
    "speed = \"fast-learn\"\n",
    "workers = 8\n",
    "odbc_conn = odbc_connect()\n",
    "model_level = \"TopLevelDispatcher\"\n",
    "min_date = \"2021-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_traffic_text(percent):\n",
    "    return str(percent) if int(percent) >= 10 else \"0\" + str(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_traffic_text(\"3\") == \"03\"\n",
    "assert get_traffic_text(\"13\") == \"13\"\n",
    "assert get_traffic_text(\"78\") == \"78\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_experiment_segment(traffic_percent):\n",
    "    return tuple(get_traffic_text(tp) for tp in range(traffic_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_experiment_segment(1) == (\"00\",)\n",
    "assert get_experiment_segment(3) == (\"00\", \"01\", \"02\")\n",
    "assert \"' '\".join(get_experiment_segment(1)) == \"00\"\n",
    "assert f\"\"\"IN ('{\"','\".join(get_experiment_segment(3))}')\"\"\" == \"IN ('00','01','02')\"\n",
    "assert len(get_experiment_segment(50)) == 50\n",
    "assert max([int(x) for x in get_experiment_segment(100)]) == 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_utterances(odbc_conn, model, min_date, traffic_percent):\n",
    "    segment = get_experiment_segment(traffic_percent)\n",
    "    return query(\n",
    "        odbc_conn,\n",
    "        f\"\"\"\n",
    "    select Utterance from \"chatbot_unpublish_s3\".\"lambda-output\".\"finn_feedback\"\n",
    "    where model = '{model}' and to_date(substr(\"Timestamp\", 0, 10), 'YYYY-MM-dd') >= to_date('{min_date}', 'YYYY-MM-dd')\n",
    "    and substr(AccountNumber, 15, 16) IN ('{\"','\".join(segment)}')\n",
    "    \"\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_button_responses_filter(odbc_conn):\n",
    "    button_responses_query = f\"\"\"\n",
    "    SELECT \"text\"\n",
    "    FROM \"chatbot_unpublish_s3\".\"lambda-output\".\"live_person\".messages a\n",
    "    inner join \"chatbot_unpublish_s3\".\"lambda-output\".digital.events b\n",
    "    on a.\"conversationId\" = b.\"LivePersonConversationId\"\n",
    "    where b.QuickReplyButton = true and a.eventBy = 'Consumer'\n",
    "    \"\"\"\n",
    "    button_responses = query(odbc_conn, button_responses_query)\n",
    "    additional_button_responses = [\n",
    "        \"Transaction enquiry\",\n",
    "        \"Transaction Enquiry\",\n",
    "        \"Hi\",\n",
    "        \"Hello\",\n",
    "        \"Card declined\",\n",
    "        \"Close account\",\n",
    "    ]\n",
    "    return button_responses.text.tolist() + additional_button_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportn_step:preprocess\n",
    "\n",
    "\n",
    "def preprocess(odbc_conn, model_level, min_date, traffic_percent):\n",
    "    data = get_utterances(odbc_conn, model_level, min_date, traffic_percent)\n",
    "    button_filter = get_button_responses_filter(odbc_conn)\n",
    "    user_texts = data[~data.Utterance.isin(button_filter)].copy()\n",
    "    documents = user_texts.Utterance.tolist()\n",
    "    results = {\"documents\": documents}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = preprocess(odbc_conn, model_level, min_date, traffic_percent)[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(documents) > 0\n",
    "assert (\n",
    "    pd.Series([\"Transaction Enquiry\", \"Payment Issues\", \"Credit Limit Enquiry\"])\n",
    "    .isin(pd.Series(documents))\n",
    "    .sum()\n",
    "    == 0\n",
    ")  # no button response texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Topics:\n",
    "    def __init__(self, documents, workers, speed):\n",
    "        pass\n",
    "\n",
    "    def get_num_topics(self):\n",
    "        return 6\n",
    "\n",
    "    def get_topic_sizes(self):\n",
    "        return [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    def get_topics(self, num_topics):\n",
    "        return (\n",
    "            [\"cat\", \"sat\", \"mat\", \"mouse\", \"house\", \"grouse\"],\n",
    "            np.asarray([1, 1, 1, 1, 1, 1]),\n",
    "            [1, 2, 3, 4, 5, 6],\n",
    "        )\n",
    "\n",
    "    def search_documents_by_topic(self, topic_num, num_docs):\n",
    "        return (\n",
    "            [\"cat\", \"sat\", \"mat\", \"mouse\", \"house\", \"grouse\"],\n",
    "            np.asarray([1, 1, 1, 1, 1, 1]),\n",
    "            [1, 2, 3, 4, 5, 6],\n",
    "        )\n",
    "\n",
    "    def generate_topic_wordcloud(self, topic_num):\n",
    "        print(\"wordcloud\")\n",
    "\n",
    "    def hierarchical_topic_reduction(self, num_topics):\n",
    "        return [\"cat\", \"sat\", \"mat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportn_step:fit\n",
    "\n",
    "\n",
    "def fit(documents, workers=workers, speed=\"fast-learn\"):\n",
    "    model = Topics(documents, workers=workers, speed=speed)\n",
    "    results = {\"model\": model}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "import time\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(documents, workers=workers, speed=speed)[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_num_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "assert all([s > 0 for s in topic_sizes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Topic Words & Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "assert len(topic_words) == model.get_num_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Representative Documents for Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_num_docs(topic_idx, topic_sizes, max_k=50):\n",
    "    n_docs = topic_sizes[topic_idx]\n",
    "    return n_docs if n_docs < max_k else max_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance in word space & in intent space\n",
    "# Topics matches to sub-intent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(model.get_num_topics(), 1)[0]\n",
    "docs, doc_scores, doc_ids = model.search_documents_by_topic(\n",
    "    topic_num=i, num_docs=get_num_docs(i, topic_sizes, max_k=20)\n",
    ")\n",
    "\n",
    "assert all([type(doc) == str for doc in docs])\n",
    "assert all([type(doc.encode(\"utf-8\")) == bytes for doc in docs])\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis\n",
    "# time.sleep(120)\n",
    "model.generate_topic_wordcloud(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportn_step:evaluate\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    topic_words, word_scores, topic_nums = model.get_topics(model.get_num_topics())\n",
    "\n",
    "    topic_contains_non_empty_words = all([len(tw) > 0 for tw in topic_words])\n",
    "    word_scores_in_range = word_scores.min() >= 0.0 and word_scores.max() <= 1.0\n",
    "    as_many_items_as_topics = (\n",
    "        model.get_num_topics() == len(topic_words) == word_scores.shape[0]\n",
    "    )\n",
    "    results = (\n",
    "        topic_contains_non_empty_words\n",
    "        and word_scores_in_range\n",
    "        and as_many_items_as_topics\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def serve_num_topics(model):\n",
    "    return model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert serve_num_topics(model) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def serve_reduced_hierarchies(model, desired_num_topics):\n",
    "    return model.hierarchical_topic_reduction(desired_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    serve_reduced_hierarchies(model, -1)\n",
    "except IndexError:\n",
    "    print(\"Negative indexing not possible\")\n",
    "try:\n",
    "    serve_reduced_hierarchies(model, model.get_num_topics() + 1)  # > #topics\n",
    "except ValueError as ve:\n",
    "    print(ve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sciflow]",
   "language": "python",
   "name": "conda-env-sciflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
