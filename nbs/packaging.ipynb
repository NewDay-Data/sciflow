{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified conda & pip packaging & deployment\n",
    "\n",
    "> Package management can be challenging for Data Science workflows. Many enterprises will not be able to publish all their packages to public repositories like pypi or conda. Different stages of the Data Science lifecycle require different capabilities with respect to library management. Early stage research values flexibility and the ability to add the latest packages on the fly. Production models want reliability and known, fixed dependencies. This module aims to make it easier to meet these goals.\n",
    "\n",
    "# 1. Determine minimal dependencies\n",
    "\n",
    "We are explicit about the code that makes up the Data Science workflow using the sciflow steps/flows method. This helps extract the virtual environments which are needed to run the flows & allows downstream processes to have a reliable (pinned) version of dependencies that work for a workflow instance.\n",
    "\n",
    "## 1.1 Dependency Calculation\n",
    "* [pigar](https://github.com/damnever/pigar): the pigar library is used to calculate the dependencies used of all moduels in the `sciflow` lib.\n",
    "\n",
    "# 2. Making It Easier\n",
    "\n",
    "Additions to `Makefile`\n",
    "\n",
    "```\n",
    "local_release: art_pip art_conda\n",
    "art_pip: deploy to private artifactory pypi repository\n",
    "art_conda: deploy to private artifactory conda channel\n",
    "```\n",
    "\n",
    "The `sciflow_prepare` command is used to prepare the environment with any auithentication details that are needed for package management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from configparser import ConfigParser\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import yaml\n",
    "from fastcore.script import call_parse\n",
    "from nbdev.export import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def reqs_file_to_sep_str(pip_reqs_path: Path) -> str:\n",
    "    with open(pip_reqs_path, \"r\") as pip_reqs_file:\n",
    "        lines = pip_reqs_file.readlines()\n",
    "    return reqs_lines_to_sep_str(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_py_module(command, args, cwd, env=None):\n",
    "\n",
    "    output = subprocess.run(\n",
    "        [sys.executable, \"-m\", command, *(str(i).strip() for i in args)],\n",
    "        stderr=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        cwd=cwd,\n",
    "        env=env,\n",
    "        universal_newlines=True,\n",
    "    )\n",
    "\n",
    "    output_code = output.returncode\n",
    "    output.stdout\n",
    "    err = output.stderr\n",
    "\n",
    "    if output_code != 0:\n",
    "        raise EnvironmentError(err)\n",
    "    return output_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def determine_dependencies(\n",
    "    out_dir: Path = None, generated_pip_file_name: str = \"requirements-generated.txt\"\n",
    "):\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        print(\"Pigar dependency is not installed - not able to determine dependencies\")\n",
    "        return\n",
    "    lib_path = Config().path(\"lib_path\")\n",
    "    if out_dir is None:\n",
    "        out_dir = lib_path.resolve().parent\n",
    "\n",
    "    command = \"pigar\"\n",
    "    args = [\"-p\", generated_pip_file_name, \"-P\", lib_path]\n",
    "\n",
    "    run_py_module(command, args, out_dir)\n",
    "\n",
    "    return reqs_file_to_sep_str(os.path.join(out_dir, generated_pip_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def reqs_lines_to_sep_str(req_lines: List[str], sep: str = \" \"):\n",
    "    return \" \".join(\n",
    "        [\n",
    "            l.replace(\" \", \"\").strip()\n",
    "            for l in req_lines\n",
    "            if not l.startswith(\"#\") and len(l.strip()) > 0\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path(\"test\").resolve()\n",
    "generated_reqs_path = os.path.join(test_dir, \"requirements-generated.txt\")\n",
    "if os.path.exists(generated_reqs_path):\n",
    "    os.remove(generated_reqs_path)\n",
    "assert not os.path.exists(generated_reqs_path)\n",
    "determine_dependencies(out_dir=test_dir)\n",
    "assert os.path.exists(generated_reqs_path)\n",
    "os.remove(generated_reqs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement.txt Manipulation\n",
    "\n",
    "> Read pip requirements file and convert to a structure that can be used to transform that output to a different format.\n",
    "\n",
    "For more information see here:\n",
    "\n",
    "https://www.python.org/dev/peps/pep-0440/#version-specifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = (\n",
    "    \"fastcore == 1.3.19\",\n",
    "    \"\\n\",\n",
    "    \"#\",\n",
    "    \"nbformat >= 5.0.8\",\n",
    "    \"# scidev/nb_lint.py: 10,11,12\",\n",
    "    \"nbqa ~= 0.5.6\",\n",
    "    \"nbqa <=0.5.6\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    \"fastcore==1.3.19 nbformat>=5.0.8 nbqa~=0.5.6 \"\n",
    "    \"nbqa<=0.5.6\" == reqs_lines_to_sep_str(test_lines)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "determine_dependencies(out_dir=test_dir)\n",
    "reqs_str = reqs_file_to_sep_str(generated_reqs_path)\n",
    "os.remove(generated_reqs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def update_requirements(\n",
    "    project_dir: Path = None, output_filename: str = \"settings.ini\"\n",
    "):\n",
    "    if project_dir is None:\n",
    "        lib_path = Config().path(\"lib_path\")\n",
    "        project_dir = lib_path.resolve().parent\n",
    "\n",
    "    config = ConfigParser(delimiters=[\"=\"])\n",
    "    settings_path = os.path.join(project_dir, \"settings.ini\")\n",
    "    config.read(settings_path)\n",
    "\n",
    "    os.path.join(project_dir, \"requirements-generated.txt\")\n",
    "    reqs_str = determine_dependencies(out_dir=project_dir)\n",
    "\n",
    "    out_path = os.path.join(project_dir, output_filename)\n",
    "    config.set(\"DEFAULT\", \"requirements\", reqs_str)\n",
    "\n",
    "    with open(out_path, \"w\") as configfile:\n",
    "        config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "determine_dependencies(out_dir=test_dir)\n",
    "update_requirements(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser(delimiters=[\"=\"])\n",
    "test_config_file = os.path.join(test_dir, \"settings.ini\")\n",
    "config.read(test_config_file)\n",
    "assert \"nbdev\" in config.get(\"DEFAULT\", \"requirements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_keys = (\n",
    "    \"lib_name\",\n",
    "    \"description\",\n",
    "    \"version\",\n",
    "    \"custom_sidebar\",\n",
    "    \"license\",\n",
    "    \"status\",\n",
    "    \"console_scripts\",\n",
    "    \"nbs_path\",\n",
    "    \"lib_path\",\n",
    "    \"title\",\n",
    "    \"tst_flags\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([config.get(\"DEFAULT\", k) is not None for k in required_keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create conda build file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def create_conda_meta_file(project_dir: Path = None, out_file: str = \"meta.yaml\"):\n",
    "    if project_dir is None:\n",
    "        lib_path = Config().path(\"lib_path\")\n",
    "        project_dir = lib_path.resolve().parent\n",
    "\n",
    "    meta_data = {\n",
    "        \"package\": {\n",
    "            \"name\": Config().get(\"lib_name\"),\n",
    "            \"version\": Config().get(\"version\"),\n",
    "        },\n",
    "        \"source\": {\"path\": str(Config().path(\"lib_path\").resolve().parent)},\n",
    "        \"requirements\": {\n",
    "            \"host\": [\"pip\", \"python\", \"setuptools\"],\n",
    "            \"run\": determine_dependencies(out_dir=project_dir).split(\" \"),\n",
    "        },\n",
    "    }\n",
    "    with open(os.path.join(project_dir, out_file), \"w\") as conda_build_file:\n",
    "        yaml.dump(meta_data, conda_build_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_conda_meta_file(Path(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update All Project Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_update_reqs():\n",
    "    create_conda_meta_file()\n",
    "    update_requirements()\n",
    "    print(\"Updated library requirements for conda & nbdev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated library requirements for conda & nbdev\n"
     ]
    }
   ],
   "source": [
    "sciflow_update_reqs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Artifactory Environment\n",
    "\n",
    "> This code should be in projects not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def delete_multiple_element(list_object, indices):\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def read_deploy_vars():\n",
    "    with open(os.path.join(Path.home(), \".condarc\"), \"r\") as conda_rc_file:\n",
    "        conda_rc = yaml.load(conda_rc_file, Loader=yaml.FullLoader)\n",
    "        conda_url = conda_rc[\"channels\"][0]\n",
    "    deployment = {\n",
    "        \"conda_url\": conda_url,\n",
    "        \"artifactory_user\": urlparse(conda_url).netloc.split(\":\")[0],\n",
    "        \"artifactory_token\": urlparse(conda_url).netloc.split(\":\")[1].split(\"@\")[0],\n",
    "        \"artifactory_url\": urlparse(conda_url).netloc.split(\":\")[1].split(\"@\")[1],\n",
    "        \"artifactory_conda_channel\": \"conda-local\",\n",
    "        \"lib_name\": Config().lib_name,\n",
    "        \"version\": Config().version,\n",
    "        \"build_number\": 0,\n",
    "    }\n",
    "    return deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_vars = read_deploy_vars()\n",
    "assert deploy_vars[\"lib_name\"] == \"sciflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_art_conda_envs_to_file():\n",
    "    dep_vars = read_deploy_vars()\n",
    "\n",
    "    with open(os.path.join(Path.home(), \".profile\"), \"r\") as profile_file:\n",
    "        existing_lines = profile_file.readlines()\n",
    "        to_remove = []\n",
    "        for i, line in enumerate(existing_lines):\n",
    "            if (\n",
    "                line.strip().startswith(\"export ARTIFACTORY_\")\n",
    "                or line.strip().startswith(\"export LIB_NAME\")\n",
    "                or line.strip().startswith(\"export VERSION\")\n",
    "                or line.strip().startswith(\"export BUILD_NUMBER\")\n",
    "            ):\n",
    "                to_remove.append(i)\n",
    "            if not line.endswith(\"\\n\"):\n",
    "                existing_lines[i] = line + \"\\n\"\n",
    "        delete_multiple_element(existing_lines, to_remove)\n",
    "\n",
    "    with open(os.path.join(Path.home(), \".profile\"), \"w\") as profile_file:\n",
    "        new_lines = [\n",
    "            \"export ARTIFACTORY_USER={artifactory_user}\\n\".format(**dep_vars),\n",
    "            \"export ARTIFACTORY_PASSWORD={artifactory_token}\\n\".format(**dep_vars),\n",
    "            \"export ARTIFACTORY_URL={artifactory_url}\\n\".format(**dep_vars),\n",
    "            \"export ARTIFACTORY_CONDA_CHANNEL={artifactory_conda_channel}\\n\".format(\n",
    "                **dep_vars\n",
    "            ),\n",
    "            \"export LIB_NAME={lib_name}\\n\".format(**dep_vars),\n",
    "            \"export VERSION={version}\\n\".format(**dep_vars),\n",
    "            \"export BUILD_NUMBER={build_number}\\n\".format(**dep_vars),\n",
    "        ]\n",
    "        existing_lines.extend(new_lines)\n",
    "        profile_file.writelines(existing_lines)\n",
    "    return existing_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eval \"$(conda shell.bash hook)\"\\n',\n",
       " 'source .bashrc 2>/dev/null\\n',\n",
       " 'export ARTIFACTORY_USER=nexus_eut_svc\\n',\n",
       " 'export ARTIFACTORY_PASSWORD=AKCp8hzCxcyh1Uh9s4LMNZKmEHY1V4jwUhfqRsEUvdvMNZKhyncwt8MTtzwaq2rZkhx6dxW3e\\n',\n",
       " 'export ARTIFACTORY_URL=ndartifactory.jfrog.io\\n',\n",
       " 'export ARTIFACTORY_CONDA_CHANNEL=conda-local\\n',\n",
       " 'export LIB_NAME=sciflow\\n',\n",
       " 'export VERSION=0.0.1\\n',\n",
       " 'export BUILD_NUMBER=0\\n']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = write_art_conda_envs_to_file()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(lines) >= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def correct_pypirc():\n",
    "    with open(os.path.join(Path.home(), \".pypirc\"), \"r\") as pypirc_file:\n",
    "        lines = pypirc_file.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"repository:\"):\n",
    "            repository_idx = i\n",
    "\n",
    "    lines[\n",
    "        repository_idx\n",
    "    ] = \"repository: https://ndartifactory.jfrog.io/artifactory/api/pypi/pypi\\n\"\n",
    "\n",
    "    with open(os.path.join(Path.home(), \".pypirc\"), \"w\") as pypirc_file:\n",
    "        pypirc_file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pypirc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_prepare():\n",
    "    dep_vars = read_deploy_vars()\n",
    "    correct_pypirc()\n",
    "\n",
    "    for dep_key in dep_vars.keys():\n",
    "        os.environ[dep_key.upper()] = str(dep_vars[dep_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ARTIFACTORY_CONDA_CHANNEL\" in os.environ:\n",
    "    del os.environ[\"ARTIFACTORY_CONDA_CHANNEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciflow_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"conda-local\" == os.environ[\"ARTIFACTORY_CONDA_CHANNEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sciflow]",
   "language": "python",
   "name": "conda-env-sciflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
