{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified conda & pip packaging & deployment\n",
    "\n",
    "> Package management can be challenging for Data Science workflows. Many enterprises will not be able to publish all their packages to public repositories like pypi or conda. Different stages of the Data Science lifecycle require different capabilities with respect to library management. Early stage research values flexibility and the ability to add the latest packages on the fly. Production models want reliability and known, fixed dependencies. This module aims to make it easier to meet these goals.\n",
    "\n",
    "# 1. Determine minimal dependencies\n",
    "\n",
    "We are explicit about the code that makes up the Data Science workflow using the sciflow steps/flows method. This helps extract the virtual environments which are needed to run the flows & allows downstream processes to have a reliable (pinned) version of dependencies that work for a workflow instance.\n",
    "\n",
    "## 1.1 Dependency Calculation\n",
    "* [pigar](https://github.com/damnever/pigar): the pigar library is used to calculate the dependencies used of all moduels in the `sciflow` lib.\n",
    "\n",
    "# 2. Making It Easier\n",
    "\n",
    "Additions to `Makefile`\n",
    "\n",
    "```\n",
    "local_release: art_pip art_conda\n",
    "art_pip: deploy to private artifactory pypi repository\n",
    "art_conda: deploy to private artifactory conda channel\n",
    "```\n",
    "\n",
    "## 2.1 Conda Artifactory Environment Variables needed\n",
    "\n",
    "* export ARTIFACTORY_USER=..\n",
    "* export ARTIFACTORY_PASSWORD=..\n",
    "* export ARTIFACTORY_URL=ndartifactory.jfrog.io\n",
    "* export ARTIFACTORY_CONDA_CHANNEL=conda-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from configparser import ConfigParser\n",
    "from nbdev.export import Config\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def determine_dependencies(generated_pip_file_name: str = \"requirements-generated.txt\"):\n",
    "    try:\n",
    "        pass\n",
    "    except:\n",
    "        print(\"Pigar dependency is not installed - not able to determine dependencies\")\n",
    "        return\n",
    "    lib_path = Config().path(\"lib_path\")\n",
    "    project_root = lib_path.resolve().parent\n",
    "    command = \"pigar\"\n",
    "    args = [\"-p\", generated_pip_file_name, \"-P\", lib_path]\n",
    "\n",
    "    output = subprocess.run(\n",
    "        [sys.executable, \"-m\", command, *(str(i).strip() for i in args)],\n",
    "        stderr=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        cwd=project_root,\n",
    "        env=None,\n",
    "        universal_newlines=True,\n",
    "    )\n",
    "\n",
    "    output_code = output.returncode\n",
    "\n",
    "    output.stdout\n",
    "    err = output.stderr\n",
    "\n",
    "    if output_code != 0:\n",
    "        raise EnvironmentError(err)\n",
    "        \n",
    "    return reqs_file_to_sep_str(os.path.join(project_root, generated_pip_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastcore==1.3.19 nbdev==1.1.12 nbformat==5.0.8 nbqa==0.5.6 networkx==2.5 pandas==0.25.3'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_reqs_path = os.path.join(\n",
    "    Path(\".\").resolve().parent, \"requirements-generated.txt\"\n",
    ")\n",
    "if os.path.exists(generated_reqs_path):\n",
    "    os.remove(generated_reqs_path)\n",
    "assert not os.path.exists(generated_reqs_path)\n",
    "determine_dependencies()\n",
    "assert os.path.exists(generated_reqs_path)\n",
    "os.remove(generated_reqs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement.txt Manipulation\n",
    "\n",
    "> Read pip requirements file and convert to a structure that can be used to transform that output to a different format.\n",
    "\n",
    "For more information see here:\n",
    "\n",
    "https://www.python.org/dev/peps/pep-0440/#version-specifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = (\n",
    "    \"fastcore == 1.3.19\",\n",
    "    \"\\n\",\n",
    "    \"#\",\n",
    "    \"nbformat >= 5.0.8\",\n",
    "    \"# scidev/nb_lint.py: 10,11,12\",\n",
    "    \"nbqa ~= 0.5.6\",\n",
    "    \"nbqa <=0.5.6\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reqs_lines_to_sep_str(req_lines: List[str], sep: str = \" \"):\n",
    "    return \" \".join(\n",
    "        [\n",
    "            l.replace(\" \", \"\").strip()\n",
    "            for l in req_lines\n",
    "            if not l.startswith(\"#\") and len(l.strip()) > 0\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    \"fastcore==1.3.19 nbformat>=5.0.8 nbqa~=0.5.6 \"\n",
    "    \"nbqa<=0.5.6\" == reqs_lines_to_sep_str(test_lines)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reqs_file_to_sep_str(pip_reqs_path: Path) -> str:\n",
    "    with open(pip_reqs_path, \"r\") as pip_reqs_file:\n",
    "        lines = pip_reqs_file.readlines()\n",
    "    return reqs_lines_to_sep_str(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "determine_dependencies()\n",
    "reqs_str = reqs_file_to_sep_str(generated_reqs_path)\n",
    "os.remove(generated_reqs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_requirements(output_filename: str = \"settings.ini\"):\n",
    "    config = ConfigParser(delimiters=[\"=\"])\n",
    "    settings_path = os.path.join(Path(\".\").resolve().parent, \"settings.ini\")\n",
    "    config.read(settings_path)\n",
    "\n",
    "    generated_reqs_path = os.path.join(\n",
    "        Path(\".\").resolve().parent, \"requirements-generated.txt\"\n",
    "    )\n",
    "    determine_dependencies()\n",
    "    reqs_str = reqs_file_to_sep_str(generated_reqs_path)\n",
    "    os.remove(generated_reqs_path)\n",
    "\n",
    "    out_path = os.path.join(Path(\".\").resolve().parent, output_filename)\n",
    "    config.set(\"DEFAULT\", \"requirements\", reqs_str)\n",
    "\n",
    "    with open(out_path, \"w\") as configfile:\n",
    "        config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outfile = os.path.join(Path(\".\").resolve().parent, \"settings.ini\")\n",
    "update_requirements(test_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser(delimiters=[\"=\"])\n",
    "config.read(test_outfile)\n",
    "assert('nbdev' in config.get(\"DEFAULT\", \"requirements\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_keys = (\n",
    "'lib_name',\n",
    "'description',\n",
    "'version',\n",
    "'custom_sidebar',\n",
    "'license',\n",
    "'status',\n",
    "'console_scripts',\n",
    "'nbs_path',\n",
    "'lib_path',\n",
    "'title',\n",
    "'tst_flags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all([config.get(\"DEFAULT\", k) is not None for k in required_keys]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create conda build file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package:\n",
      "  name: sciflow\n",
      "  version: 0.0.1\n",
      "requirements:\n",
      "  host:\n",
      "  - pip\n",
      "  - python\n",
      "  - setuptools\n",
      "  run:\n",
      "  - fastcore==1.3.19\n",
      "  - nbdev==1.1.12\n",
      "  - nbformat==5.0.8\n",
      "  - nbqa==0.5.6\n",
      "  - networkx==2.5\n",
      "  - pandas==0.25.3\n",
      "source:\n",
      "  path: /home/jovyan/git/sciflow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(meta_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conda_meta_file(out_dir: Path, out_file: str = \"meta.yaml\"):\n",
    "    meta_data  = {'package': \n",
    "              {\n",
    "                  'name': Config().get('lib_name'),\n",
    "                  'version': Config().get('version')\n",
    "              },\n",
    "              'source': {'path': str(Config().path('lib_path').resolve().parent)},\n",
    "              'requirements': {\n",
    "                  'host': ['pip', 'python', 'setuptools'],\n",
    "                  'run': determine_dependencies().split(' ')\n",
    "              },\n",
    "             }\n",
    "    with open(os.path.join(out_dir, out_file), 'w') as conda_build_file:\n",
    "        yaml.dump(meta_data, conda_build_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_conda_meta_file(Path('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. Create meta.yaml from settings.ini\n",
    "2. Test local_conda_release\n",
    "3. Test release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-discovery]",
   "language": "python",
   "name": "conda-env-jovyan-discovery-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
