{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Converts from a `sciflow` format notebook to a `metaflow` flow.\n",
    "output-file: to_metaflow.html\n",
    "title: Sciflow Notebook to MetaFlow Flow\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | default_exp converters.to_metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from importlib import reload\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "from execnb.nbio import read_nb\n",
    "from fastcore.script import Param, bool_arg, call_parse\n",
    "from nbdev.config import get_config\n",
    "from nbdev.doclinks import nbglob\n",
    "from scilint.utils import configure_logging\n",
    "\n",
    "from sciflow.params import ParamMeta, extract_param_meta, params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_module_only, extract_steps\n",
    "from sciflow.utils import (\n",
    "    find_default_export,\n",
    "    get_flow_path,\n",
    "    indent_multiline,\n",
    "    prepare_env,\n",
    "    titleize,\n",
    ")\n",
    "\n",
    "reload(logging)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbs_dir = Path(\".\").resolve().parent\n",
    "test_dir = Path(nbs_dir, \"test\")\n",
    "nb_path = Path(test_dir, \"test_export.ipynb\")\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "configure_logging(\"debug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `rename_steps_for_metaflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def rename_steps_for_metaflow(steps):\n",
    "    for i, step in enumerate(steps):\n",
    "        if i == 0:\n",
    "            step.name = \"start\"\n",
    "        elif i == len(steps) - 1:\n",
    "            step.name = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_steps = extract_steps(os.path.join(get_config().path(\"lib_path\"), f\"_modidx.py\"))\n",
    "assert len(no_steps) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert [\"first\", \"preprocess\", \"train\", \"last\"] == [step.name for step in steps]\n",
    "rename_steps_for_metaflow(steps)\n",
    "assert [\"start\", \"preprocess\", \"train\", \"end\"] == [step.name for step in steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Single Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `nb_to_metaflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def nb_to_metaflow(nb_path: Path, flow_path: Path, silent=True):\n",
    "    nb = read_nb(nb_path)\n",
    "    lib_name = get_config().get(\"lib_name\")\n",
    "    module_name = find_default_export(nb[\"cells\"])\n",
    "    if not module_name:\n",
    "        logger.debug(f\"Ignoring conversion for nb with no default export: {nb_path}\")\n",
    "        return\n",
    "    module_name = module_name\n",
    "    path_sep_module_name = module_name.replace(\".\", \"/\")\n",
    "    nb_name = os.path.basename(nb_path)\n",
    "    exported_module = os.path.join(\n",
    "        get_config().path(\"lib_path\"), f\"{path_sep_module_name}.py\"\n",
    "    )\n",
    "    steps = extract_steps(exported_module)\n",
    "    if len(steps) == 0:\n",
    "        logger.debug(f\"Ignoring conversion for nb with no named steps: {nb_path}\")\n",
    "        return\n",
    "    orig_step_names = [step.name for step in steps]\n",
    "    if len(steps) == 1:\n",
    "        steps.append(FuncDetails(\"end\", None, None, False, \"\", \"pass\"))\n",
    "    params = params_as_dict(nb_path)\n",
    "    if len(params) == 0:\n",
    "        logger.warn(f\"No params cell found for: {os.path.basename(nb_path)}\")\n",
    "    flow_class_name = f\"{titleize(extract_module_only(module_name))}Flow\"\n",
    "    rename_steps_for_metaflow(steps)\n",
    "    write_module_to_file(\n",
    "        flow_path,\n",
    "        flow_class_name,\n",
    "        lib_name,\n",
    "        module_name,\n",
    "        orig_step_names,\n",
    "        steps,\n",
    "        params,\n",
    "    )\n",
    "    if not silent:\n",
    "        print(\n",
    "            f\"Converted {nb_name} to {flow_class_name} in: {os.path.basename(flow_path)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `write_module_to_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def write_module_to_file(\n",
    "    flow_path: Path,\n",
    "    flow_class_name: str,\n",
    "    lib_name: str,\n",
    "    module_name: str,\n",
    "    orig_step_names: Iterable[str],\n",
    "    steps: Iterable[FuncDetails],\n",
    "    params: dict,\n",
    "):\n",
    "    if not os.path.exists(flow_path.parent):\n",
    "        os.mkdir(flow_path.parent)\n",
    "    fq_module_name = f\"{lib_name}.{module_name}\"\n",
    "    param_meta = extract_param_meta(fq_module_name, params)\n",
    "    with open(flow_path, \"w\") as flow_file:\n",
    "        flow_file.write(\"#!/usr/bin/env python\\n\")\n",
    "        flow_file.write(\"# coding=utf-8\\n\")\n",
    "        flow_file.write(\"# SCIFLOW GENERATED FILE - EDIT COMPANION NOTEBOOK\\n\")\n",
    "        has_mf_param = any((p.has_metaflow_param for p in param_meta.values()))\n",
    "        has_json_param = any((p.is_json_type for p in param_meta.values()))\n",
    "        mf_params_import = \"from metaflow import FlowSpec, step, current\"\n",
    "        if has_mf_param:\n",
    "            mf_params_import += \", Parameter\"\n",
    "        if has_json_param:\n",
    "            mf_params_import += \", JSONType\"\n",
    "            flow_file.write(\"import json\\n\")\n",
    "        flow_file.write(mf_params_import + \"\\n\")\n",
    "        flow_file.write(f\"from {fq_module_name} import {', '.join(orig_step_names)}\\n\")\n",
    "        if len(params) > 0:\n",
    "            flow_file.write(\n",
    "                f\"from {fq_module_name} import {', '.join(params.keys())}\\n\"\n",
    "            )\n",
    "\n",
    "        flow_file.write(f\"\\n\\nclass {flow_class_name}(FlowSpec):\\n\")\n",
    "        ind = \"    \"\n",
    "        write_params(flow_file, param_meta, ind)\n",
    "        flow_file.write(\"\\n\")\n",
    "        write_steps(flow_file, steps, orig_step_names, param_meta, ind)\n",
    "        flow_file.write(\"\\n\")\n",
    "\n",
    "        flow_file.write('if __name__ == \"__main__\":\\n')\n",
    "        flow_file.write(f\"{ind}{flow_class_name}()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `write_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def write_params(flow_file, param_metas, ind):\n",
    "    for param in param_metas.keys():\n",
    "        if param_metas[param].is_scalar:\n",
    "            flow_file.write(f\"{ind}{param} = Parameter('{param}', default={param})\\n\")\n",
    "        elif param_metas[param].is_json_type:\n",
    "            flow_file.write(\n",
    "                f\"{ind}{param} = Parameter('{param}', default=json.dumps({param}), type=JSONType)\\n\"\n",
    "            )\n",
    "        elif param_metas[param].instance_type == PosixPath:\n",
    "            flow_file.write(\n",
    "                f\"{ind}{param} = Parameter('{param}', default=str({param}))\\n\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "param_meta_dict = {\n",
    "    \"foo\": ParamMeta(\n",
    "        instance_type=str,\n",
    "        is_scalar=True,\n",
    "        is_json_type=False,\n",
    "        persist_type=\"pickle\",\n",
    "        has_metaflow_param=True,\n",
    "        has_sagemaker_param=True,\n",
    "    )\n",
    "}\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    with open(Path(temp_dir, \"flow\"), \"w\") as flow_file:\n",
    "        write_params(flow_file, param_meta_dict, \"\")\n",
    "    with open(Path(temp_dir, \"flow\"), \"r\") as written_file:\n",
    "        file_lines = written_file.readlines()\n",
    "assert file_lines == [\"foo = Parameter('foo', default=foo)\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_path = Path(test_dir, \"test_data_handling.ipynb\")\n",
    "params = params_as_dict(nb_path)\n",
    "param_meta = extract_param_meta(\"sciflow.test.test_data_handling\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert any((p.has_metaflow_param for p in param_meta.values()))\n",
    "assert any((p.is_json_type for p in param_meta.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `format_arg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def format_arg(arg, param_meta):\n",
    "    if arg in param_meta and not param_meta[arg].has_metaflow_param:\n",
    "        result = arg\n",
    "    else:\n",
    "        result = \"self.\" + arg\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"self.foo\" == format_arg(\n",
    "    \"foo\",\n",
    "    {\n",
    "        \"foo\": ParamMeta(\n",
    "            instance_type=str,\n",
    "            is_scalar=True,\n",
    "            is_json_type=False,\n",
    "            persist_type=\"pickle\",\n",
    "            has_metaflow_param=True,\n",
    "            has_sagemaker_param=True,\n",
    "        )\n",
    "    },\n",
    ")\n",
    "assert \"foo\" == format_arg(\n",
    "    \"foo\",\n",
    "    {\n",
    "        \"foo\": ParamMeta(\n",
    "            instance_type=str,\n",
    "            is_scalar=True,\n",
    "            is_json_type=False,\n",
    "            persist_type=\"pickle\",\n",
    "            has_metaflow_param=False,\n",
    "            has_sagemaker_param=True,\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `write_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def write_steps(flow_file, steps, orig_step_names, param_meta, ind):\n",
    "    for i, step in enumerate(steps):\n",
    "        flow_file.write(f\"{ind}@step\\n\")\n",
    "        flow_file.write(f\"{ind}def {step.name}(self):\\n\")\n",
    "        if step.docstring:\n",
    "            flow_file.write(f\"{indent_multiline(step.docstring, 2)}\\n\")\n",
    "\n",
    "        if i < len(orig_step_names):\n",
    "            flow_step_args = \"\"\n",
    "            if len(step.args) > 0:\n",
    "                flow_step_args = \", \".join(\n",
    "                    [format_arg(a, param_meta) for a in step.args.split(\",\")]\n",
    "                )\n",
    "            if not step.has_return:\n",
    "                flow_file.write(f\"{ind}{ind}{orig_step_names[i]}({flow_step_args})\\n\")\n",
    "            else:\n",
    "                if step.return_stmt in param_meta:\n",
    "                    raise ValueError(\n",
    "                        f\"[{os.path.basename(flow_file.name)}] step return variable {step.return_stmt} shadows a parameter name - parameters must be unique\"\n",
    "                    )\n",
    "                flow_file.write(\n",
    "                    f\"{ind}{ind}results = {orig_step_names[i]}({flow_step_args})\\n\"\n",
    "                )\n",
    "                write_track_capture(flow_file, ind, 2)\n",
    "        else:\n",
    "            flow_file.write(f\"{ind}{ind}pass\\n\")\n",
    "            flow_file.write(\"\\n\")\n",
    "        if i < len(steps) - 1:\n",
    "            next_step = steps[i + 1].name\n",
    "            flow_file.write(f\"{ind}{ind}self.next(self.{next_step})\\n\")\n",
    "        flow_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `write_track_capture`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def write_track_capture(flow_file, ind, num_indents):\n",
    "    base_ind = \"\".join(np.repeat(ind, num_indents))\n",
    "    flow_file.write(f\"{base_ind}for key in results.keys():\\n\")\n",
    "    flow_file.write(f\"{base_ind}{ind}if key in self.__dict__:\\n\")\n",
    "    flow_file.write(\n",
    "        f\"{base_ind}{ind}{ind}self.__dict__[key] = self.__dict__[key] + results[key]\\n\"\n",
    "    )\n",
    "    flow_file.write(f\"{base_ind}{ind}else:\\n\")\n",
    "    flow_file.write(f\"{base_ind}{ind}{ind}self.__dict__[key] = results[key]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "flow_stream = StringIO()\n",
    "params_meta = {\n",
    "    \"foo\": ParamMeta(\n",
    "        instance_type=str,\n",
    "        is_scalar=True,\n",
    "        is_json_type=False,\n",
    "        persist_type=\"pickle\",\n",
    "        has_metaflow_param=True,\n",
    "        has_sagemaker_param=True,\n",
    "    )\n",
    "}\n",
    "steps = [\n",
    "    FuncDetails(\n",
    "        \"first\",\n",
    "        docstring=\"none\",\n",
    "        args=\"foo\",\n",
    "        has_return=True,\n",
    "        return_stmt=\"results={'bar': 1}}\",\n",
    "        code=\"\",\n",
    "    ),\n",
    "    FuncDetails(\n",
    "        \"last\",\n",
    "        docstring=\"bla\",\n",
    "        args=\"bar\",\n",
    "        has_return=True,\n",
    "        return_stmt=\"results={'bar': 2}}\",\n",
    "        code=\"bar = [1,2,3]\",\n",
    "    ),\n",
    "]\n",
    "write_steps(flow_stream, steps, [\"first\", \"last\"], params_meta, \"    \")\n",
    "flow_stream.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected = \"\"\"\n",
    "@step\n",
    "    def first(self):\n",
    "        \\\"\\\"\\\"none\\\"\\\"\\\"\n",
    "        results = first(self.foo)\n",
    "        for key in results.keys():\n",
    "            if key in self.__dict__:\n",
    "                self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "            else:\n",
    "                self.__dict__[key] = results[key]\n",
    "        self.next(self.last)\n",
    "\n",
    "    @step\n",
    "    def last(self):\n",
    "        \\\"\\\"\\\"bla\\\"\\\"\\\"\n",
    "        results = last(self.bar)\n",
    "        for key in results.keys():\n",
    "            if key in self.__dict__:\n",
    "                self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "            else:\n",
    "                self.__dict__[key] = results[key]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert flow_stream.read().strip(\" \\n\") == expected.strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_lines = \"\"\"    \n",
    "for key in results.keys():\n",
    "    if key in self.__dict__:\n",
    "        self.__dict__[key] = self.__dict__[key] + results[key]\n",
    "    else:\n",
    "        self.__dict__[key] = results[key]\n",
    "\"\"\".strip(\n",
    "    \" \\n\"\n",
    ")\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    with open(Path(temp_dir, \"flow\"), \"w\") as flow_file:\n",
    "        write_track_capture(flow_file, \"    \", 0)\n",
    "    with open(Path(temp_dir, \"flow\"), \"r\") as written_file:\n",
    "        file_lines = written_file.readlines()\n",
    "assert \"\".join(file_lines).strip(\"\\n\") == expected_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Flow Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Path(test_dir, \"flows\", \"metaflow\", f\"test_data_handling.py\") == get_flow_path(\n",
    "    Path(test_dir, f\"test_data_handling.ipynb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepare_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_path = Path(test_dir, \"test_multistep.ipynb\")\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "steps = extract_steps(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:53:02,729 [MainThread  ] [DEBUG]  Ignoring conversion for nb with no named steps: /home/sagemaker-user/git/sciflow/nbs/test/test_multistep.ipynb\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(nb_path, get_flow_path(nb_path), silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb_path = Path(test_dir, \"test_multistep.ipynb\")\n",
    "test_flow_path = get_flow_path(Path(test_dir, \"test_multistep.ipynb\"))\n",
    "if test_flow_path.exists():\n",
    "    test_flow_path.unlink()\n",
    "assert not test_flow_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_multistep.ipynb to TestMultistepFlow in: test_multistep.py\n"
     ]
    }
   ],
   "source": [
    "nb_to_metaflow(\n",
    "    Path(test_dir, \"test_multistep.ipynb\"),\n",
    "    get_flow_path(Path(test_dir, \"test_multistep.ipynb\")),\n",
    "    silent=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_flow_path\u001b[38;5;241m.\u001b[39mexists()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert test_flow_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore notebooks without Sciflow steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_steps_path = Path(\"packaging.ipynb\")\n",
    "assert not get_flow_path(Path(nbs_dir, \"packaging.ipynb\")).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_to_metaflow(\n",
    "    Path(nbs_dir, \"packaging.ipynb\"),\n",
    "    get_flow_path(Path(nbs_dir, \"packaging.ipynb\")),\n",
    "    silent=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not get_flow_path(Path(nbs_dir, \"packaging.ipynb\")).exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Flow Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `generate_flows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def generate_flows(config=None, clear_dir=True):\n",
    "    metaflows_dir = Path(get_config().path(\"flows_path\"), \"metaflow\")\n",
    "    if not metaflows_dir.exists():\n",
    "        metaflows_dir.mkdir(parents=True)\n",
    "    if clear_dir:\n",
    "        [f.unlink() for f in metaflows_dir.iterdir() if not f.is_dir()]\n",
    "    nb_paths = nbglob()\n",
    "    for nb_path in nb_paths:\n",
    "        nb_to_metaflow(\n",
    "            nb_path,\n",
    "            get_flow_path(nb_path, config=config),\n",
    "            silent=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_export.ipynb to TestExportFlow in: test_export.py\n",
      "Converted test_module.ipynb to TestModuleFlow in: test_module.py\n",
      "No params cell found for: test_multistep_no_params.ipynb\n",
      "Converted test_multistep_no_params.ipynb to TestMultistepNoParamsFlow in: test_multistep_no_params.py\n",
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "generate_flows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sciflow_metaflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_metaflow(log_level: str = \"warn\"):\n",
    "    configure_logging(log_level)\n",
    "    generate_flows(config=get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootLogger = logging.getLogger()\n",
    "rootLogger.handlers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted test_export.ipynb to TestExportFlow in: test_export.py\n",
      "Converted test_module.ipynb to TestModuleFlow in: test_module.py\n",
      "No params cell found for: test_multistep_no_params.ipynb\n",
      "Converted test_multistep_no_params.ipynb to TestMultistepNoParamsFlow in: test_multistep_no_params.py\n",
      "Converted test_data_handling.ipynb to TestDataHandlingFlow in: test_data_handling.py\n"
     ]
    }
   ],
   "source": [
    "sciflow_metaflow(log_level=\"info\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
