{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp run_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from itertools import product\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Any, Dict, Iterable\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.script import Param, call_parse\n",
    "from nbdev.export import find_default_export, get_config, nbglob, read_nb\n",
    "\n",
    "from sciflow.data_handler import extract_param_meta\n",
    "from sciflow.params import params_as_dict\n",
    "from sciflow.parse_module import FuncDetails, extract_steps\n",
    "from sciflow.utils import prepare_env, get_flow_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify and Run Sciflow Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(os.path.join(\"test\", \"test_export.ipynb\"))\n",
    "flow_path = get_flow_path(nb_path, flow_provider=\"sagemaker\")\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "flows_dir = get_config(cfg_name=\"test/settings.ini\").path(\"flows_path\")\n",
    "flow_name = os.path.basename(test_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "\n",
    "\n",
    "# def prep_env():\n",
    "#     if \"USER\" not in os.environ:\n",
    "#         try:\n",
    "#             os.environ[\"USER\"] = os.environ[\"GIT_COMMITTER_NAME\"]\n",
    "#         except KeyError:\n",
    "#             raise EnvironmentError(\n",
    "#                 \"Sciflow requires a known user for tracked execution. Add USER or GIT_COMMITTER_NAME to Jupyter environment variables\"\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_shell_cmd(script: str):\n",
    "    pipe = subprocess.Popen(\"%s\" % script, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True)\n",
    "    output = pipe.communicate()[0]\n",
    "    return pipe, output.decode(\"utf-8\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def check_call_flow(flow_nb_path, flow_provider=\"metaflow\", flow_command=\"show\", params=None):\n",
    "    prepare_env()\n",
    "    if flow_nb_path.suffix == \".ipynb\":\n",
    "        flow_path = get_flow_path(nb_path, flow_provider=flow_provider)\n",
    "    else:\n",
    "        flow_path = flow_nb_path\n",
    "    if params:\n",
    "        args = \" \".join([f\"--{p[0]} {p[1]}\" for p in params])\n",
    "        flow_command = f\"{flow_command} {args}\"\n",
    "    \n",
    "    script = f\"python '{flow_path}' {flow_command}\"\n",
    "    pipe, output = run_shell_cmd(script)\n",
    "    return pipe.returncode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(nb_path, flow_provider = 'metaflow', flow_command = 'show')\n",
    "assert(ret_code==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.5.2 executing TestExportFlow for user:'Donal Simmie'\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint is happy!\n",
      "2022-05-10 06:18:50.611 Workflow starting (run-id 1652163530336451):\n",
      "2022-05-10 06:18:50.675 [1652163530336451/start/1 (pid 32463)] Task is starting.\n",
      "2022-05-10 06:18:55.396 [1652163530336451/start/1 (pid 32463)] 3\n",
      "2022-05-10 06:18:55.756 [1652163530336451/start/1 (pid 32463)] Task finished successfully.\n",
      "2022-05-10 06:18:55.840 [1652163530336451/preprocess/2 (pid 32466)] Task is starting.\n",
      "2022-05-10 06:19:00.550 [1652163530336451/preprocess/2 (pid 32466)] Preprocessing input data from /home/sagemaker-user/git/sciflow/nbs...\n",
      "2022-05-10 06:19:01.919 [1652163530336451/preprocess/2 (pid 32466)] Task finished successfully.\n",
      "2022-05-10 06:19:02.010 [1652163530336451/train/3 (pid 32469)] Task is starting.\n",
      "2022-05-10 06:19:06.731 [1652163530336451/train/3 (pid 32469)] Training /home/sagemaker-user/git/sciflow on /home/sagemaker-user/git/sciflow/nbs...\n",
      "2022-05-10 06:19:08.056 [1652163530336451/train/3 (pid 32469)] Task finished successfully.\n",
      "2022-05-10 06:19:08.135 [1652163530336451/last/4 (pid 32472)] Task is starting.\n",
      "2022-05-10 06:19:13.193 [1652163530336451/last/4 (pid 32472)] Task finished successfully.\n",
      "2022-05-10 06:19:13.271 [1652163530336451/end/5 (pid 32475)] Task is starting.\n",
      "2022-05-10 06:19:18.316 [1652163530336451/end/5 (pid 32475)] Task finished successfully.\n",
      "2022-05-10 06:19:18.330 Done!\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "ret_code, output = check_call_flow(nb_path, flow_provider = 'metaflow', flow_command = 'run')\n",
    "assert(ret_code==0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(nb_path, flow_provider = 'sagemaker', flow_command = 'show')\n",
    "assert(ret_code==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sciflow generated pipeline: pipeline-2022-05-10-06-54-03-180\n",
      "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/g7umlpneq9uv', 'PipelineExecutionDisplayName': 'execution-1652165647036', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 10, 6, 54, 6, 678000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 10, 6, 54, 6, 678000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '3b0db9e1-5215-41df-83db-760831e32c8b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3b0db9e1-5215-41df-83db-760831e32c8b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Tue, 10 May 2022 06:54:07 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# slow \n",
    "\n",
    "ret_code, output = check_call_flow(nb_path, flow_provider = 'sagemaker', flow_command = 'run')\n",
    "assert(ret_code==0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Pass params into a sagemaker workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_call_flows(\n",
    "    config, flow_provider = 'metaflow', flow_command=\"show\", ignore_suffix=None, exit_on_error=True\n",
    "):\n",
    "    flow_results = {}\n",
    "    flows_dir = Path(config.path(\"flows_path\"), flow_provider)\n",
    "    \n",
    "    if ignore_suffix:\n",
    "        flow_file_names = [p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)]\n",
    "    else:\n",
    "        flow_file_names = os.listdir(flows_dir)\n",
    "    ret_codes = []\n",
    "    exit_code = 0\n",
    "    for flow_file_name in flow_file_names:\n",
    "        flow_name = os.path.basename(flow_file_name)\n",
    "        if flow_file_name.startswith('_sciflow'):\n",
    "            continue\n",
    "        if flow_file_name.endswith(\".py\"):\n",
    "            ret_code, output = check_call_flow(Path(flows_dir, flow_file_name), flow_command=flow_command)\n",
    "            flow_results[flow_name] = ret_code, output\n",
    "            if ret_code == 0:\n",
    "                print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "                )\n",
    "            ret_codes.append(ret_code)\n",
    "    if any([rc != 0 for rc in ret_codes]):\n",
    "        exit_code = 1\n",
    "        try:\n",
    "            # Exit with an error code if running from a non interactive Python environment.\n",
    "            get_ipython().__class__.__name__\n",
    "        except NameError:\n",
    "            if exit_on_error:\n",
    "                return sys.exit(exit_code)\n",
    "    return exit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_multistep.py --no-pylint run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"), flow_command=\"--no-pylint run\", ignore_suffix=\"_no_params.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"), flow_provider=\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.5.2 executing TestMultistepFlow for user:'Donal Simmie'\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint is happy!\n",
      "2022-05-10 07:15:15.127 Workflow starting (run-id 1652166914856693):\n",
      "2022-05-10 07:15:15.191 [1652166914856693/start/1 (pid 1879)] Task is starting.\n",
      "2022-05-10 07:15:16.581 [1652166914856693/start/1 (pid 1879)] The first step\n",
      "2022-05-10 07:15:17.000 [1652166914856693/start/1 (pid 1879)] Task finished successfully.\n",
      "2022-05-10 07:15:17.089 [1652166914856693/preprocess/2 (pid 1886)] Task is starting.\n",
      "2022-05-10 07:15:18.488 [1652166914856693/preprocess/2 (pid 1886)] I captialised the message: THE FIRST STEP\n",
      "2022-05-10 07:15:18.943 [1652166914856693/preprocess/2 (pid 1886)] Task finished successfully.\n",
      "2022-05-10 07:15:19.028 [1652166914856693/fit/3 (pid 1893)] Task is starting.\n",
      "2022-05-10 07:15:20.896 [1652166914856693/fit/3 (pid 1893)] Task finished successfully.\n",
      "2022-05-10 07:15:20.977 [1652166914856693/evaluate/4 (pid 1900)] Task is starting.\n",
      "2022-05-10 07:15:22.892 [1652166914856693/evaluate/4 (pid 1900)] Task finished successfully.\n",
      "2022-05-10 07:15:22.978 [1652166914856693/end/5 (pid 1907)] Task is starting.\n",
      "2022-05-10 07:15:24.912 [1652166914856693/end/5 (pid 1907)] Task finished successfully.\n",
      "2022-05-10 07:15:24.928 Done!\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "nb_path = Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\")\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path,\n",
    "    flow_command = 'run',\n",
    "    params=[(\"traffic_percent\", 1), (\"model_level\", \"dispatcher\")],\n",
    ")\n",
    "print(output)\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [WIP] Aynsc Flow Running\n",
    "\n",
    "> Run the flow you are working on from the notebook you are working on. This maximises the amount of experiments you can run as you don't have down time. While long running tasks are running you can keep exploring! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def run_flow_task(flow_path, param_grid=None):\n",
    "    flows_dir = flow_path.parent\n",
    "    flow_module = os.path.basename(flow_path)\n",
    "    flow_command = \"--no-pylint run\"\n",
    "    prep_mf_env()\n",
    "    if params:\n",
    "        args = \" \".join([f\"--{k} {v}\" for k, v in param_grid.items()])\n",
    "        cmd = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command} {args}\"\n",
    "    else:\n",
    "        cmd = f\"python '{os.path.join(flows_dir, flow_module)}' {flow_command}\"\n",
    "    proc = await asyncio.create_subprocess_shell(\n",
    "        cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    stdout, stderr = await proc.communicate()\n",
    "\n",
    "    print(f\"[{cmd!r} exited with {proc.returncode}]\")\n",
    "    if stdout:\n",
    "        output = stdout.decode(\"utf-8\").strip()\n",
    "        print(f\"[stdout]\\n{output}\")\n",
    "    if stderr:\n",
    "        print(f'[stderr]\\n{stderr.decode(\"utf-8\").strip()}')\n",
    "\n",
    "    return proc.returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_flow_async(nb_path, params=None):\n",
    "    flow_path = get_flow_path(nb_path)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(run_flow_task(flow_path, params))\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flow_async(\n",
    "    os.path.join(\"test\", \"test_multistep.ipynb\"),\n",
    "    params={\"traffic_percent\": 10, \"workers\": 12},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"traffic_percent\": [1, 5, 10, 20, 50, 100],\n",
    "    \"model_level\": [\"router\", \"dispatcher\"],\n",
    "    \"workers\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def iter_param_grid(param_grid):\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/model_selection/_search.py\n",
    "    for p in [param_grid]:\n",
    "        # Always sort the keys of a dictionary, for reproducibility\n",
    "        items = sorted(p.items())\n",
    "        if not items:\n",
    "            yield {}\n",
    "        else:\n",
    "            keys, values = zip(*items)\n",
    "            for v in product(*values):\n",
    "                params = dict(zip(keys, v))\n",
    "                yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [{\"a\": 1, \"b\": 1, \"c\": \"hello\"}, {\"a\": 2, \"b\": 1, \"c\": \"hello\"}] == list(\n",
    "    iter_param_grid({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def sample_grid_space(param_grid: Dict[str, Iterable[Any]], num_samples: int):\n",
    "    samples = []\n",
    "    for i, sample in enumerate(iter_param_grid(param_grid)):\n",
    "        samples.append(sample)\n",
    "    if num_samples < len(samples):\n",
    "        samples = pd.Series(samples).sample(num_samples).tolist()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = sample_grid_space({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]}, 1)\n",
    "assert sample_space[0][\"b\"] == 1\n",
    "assert sample_space[0][\"c\"] == \"hello\"\n",
    "assert sample_space[0][\"a\"] == 1 or sample_space[0][\"a\"] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def search_flow_grid(nb_path, param_grid, num_procs=None):\n",
    "    if num_procs is None:\n",
    "        num_procs = int((multiprocessing.cpu_count() / 2) - 1)\n",
    "\n",
    "    param_sample_space = sample_grid_space(param_grid, num_procs)\n",
    "    tasks = []\n",
    "    for param_sample in param_sample_space:\n",
    "        tasks.append(run_flow_async(nb_path, params=param_sample))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "nb_path = Path(\n",
    "    Path(\".\").resolve(),\n",
    "    \"test\",\n",
    "    \"test_multistep.ipynb\",\n",
    ")\n",
    "tasks = search_flow_grid(\n",
    "    nb_path,\n",
    "    {\n",
    "        \"traffic_percent\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50],\n",
    "        \"model_level\": [\"dispatcher\"],\n",
    "        \"workers\": [1],\n",
    "    },\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "[t.done() for t in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "[t.result() for t in tasks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folding @ Home Type Exploration\n",
    "\n",
    "> Explore wider search space in background. Try to always be making some use of resource. Needs persistent search space tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_flows():\n",
    "    check_flows(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_flows():\n",
    "    check_flows(get_config(), \"--no-pylint run\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "sciflow (sciflow/3)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:368653567616:image-version/sciflow/3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
