{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp run_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.script import call_parse\n",
    "from nbdev.export import find_default_export, get_config, read_nb\n",
    "\n",
    "from sciflow.utils import chunks, get_flow_path, prepare_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify and Run Sciflow Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(Path(\".\").resolve(), \"test\", \"test_export.ipynb\")\n",
    "flow_path = get_flow_path(nb_path, flow_provider=\"sagemaker\")\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "flows_dir = get_config(cfg_name=\"test/settings.ini\").path(\"flows_path\")\n",
    "flow_name = os.path.basename(test_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify or Run an Individual Flow\n",
    "\n",
    "> `subprocess` is used to run flows as most flow providers bundle a CLI which makes for a consistent execution experience with minimal adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_shell_cmd(script: str):\n",
    "    pipe = subprocess.Popen(\n",
    "        \"%s\" % script, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True\n",
    "    )\n",
    "    output = pipe.communicate()[0]\n",
    "    return pipe, output.decode(\"utf-8\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def make_shell_cmd(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"show\", params=None\n",
    "):\n",
    "    prepare_env()\n",
    "    if flow_nb_path.suffix == \".ipynb\":\n",
    "        flow_path = get_flow_path(flow_nb_path, flow_provider=flow_provider)\n",
    "    else:\n",
    "        flow_path = flow_nb_path\n",
    "    if params:\n",
    "        args = \" \".join([f\"--{k} {v}\" for k, v in params.items()])\n",
    "\n",
    "        flow_command = f\"{flow_command} {args}\"\n",
    "\n",
    "    return f\"python '{flow_path}' {flow_command}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_call_flow(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"show\", params=None\n",
    "):\n",
    "    cmd = make_shell_cmd(flow_nb_path, flow_provider, flow_command, params)\n",
    "    pipe, output = run_shell_cmd(cmd)\n",
    "    return pipe.returncode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"metaflow\", flow_command=\"show\"\n",
    ")\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.5.2 executing TestExportFlow for user:'Donal Simmie'\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint is happy!\n",
      "2022-05-11 06:20:23.231 Workflow starting (run-id 1652250022971798):\n",
      "2022-05-11 06:20:23.293 [1652250022971798/start/1 (pid 8965)] Task is starting.\n",
      "2022-05-11 06:20:28.021 [1652250022971798/start/1 (pid 8965)] 3\n",
      "2022-05-11 06:20:28.344 [1652250022971798/start/1 (pid 8965)] Task finished successfully.\n",
      "2022-05-11 06:20:28.424 [1652250022971798/preprocess/2 (pid 8968)] Task is starting.\n",
      "2022-05-11 06:20:33.153 [1652250022971798/preprocess/2 (pid 8968)] Preprocessing input data from /home/sagemaker-user/git/sciflow/nbs...\n",
      "2022-05-11 06:20:34.490 [1652250022971798/preprocess/2 (pid 8968)] Task finished successfully.\n",
      "2022-05-11 06:20:34.573 [1652250022971798/train/3 (pid 8971)] Task is starting.\n",
      "2022-05-11 06:20:39.297 [1652250022971798/train/3 (pid 8971)] Training /home/sagemaker-user/git/sciflow on /home/sagemaker-user/git/sciflow/nbs...\n",
      "2022-05-11 06:20:40.612 [1652250022971798/train/3 (pid 8971)] Task finished successfully.\n",
      "2022-05-11 06:20:40.703 [1652250022971798/last/4 (pid 8974)] Task is starting.\n",
      "2022-05-11 06:20:45.762 [1652250022971798/last/4 (pid 8974)] Task finished successfully.\n",
      "2022-05-11 06:20:45.837 [1652250022971798/end/5 (pid 8977)] Task is starting.\n",
      "2022-05-11 06:20:50.954 [1652250022971798/end/5 (pid 8977)] Task finished successfully.\n",
      "2022-05-11 06:20:50.969 Done!\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"metaflow\", flow_command=\"run\"\n",
    ")\n",
    "assert ret_code == 0\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"sagemaker\", flow_command=\"show\"\n",
    ")\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sciflow generated pipeline: pipeline-2022-05-11-06-23-18-450\n",
      "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/jkax8pbvfgdh', 'PipelineExecutionDisplayName': 'execution-1652250202244', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 6, 23, 22, 151000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 6, 23, 22, 151000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': 'd787e8a3-0d6f-48fb-8f04-2540f4760267', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd787e8a3-0d6f-48fb-8f04-2540f4760267', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 06:23:22 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"sagemaker\", flow_command=\"run\"\n",
    ")\n",
    "assert ret_code == 0\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify/Run all Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_call_flows(\n",
    "    config,\n",
    "    flow_provider=\"metaflow\",\n",
    "    flow_command=\"show\",\n",
    "    ignore_suffix=None,\n",
    "    exit_on_error=True,\n",
    "):\n",
    "    flow_results = {}\n",
    "    flows_dir = Path(config.path(\"flows_path\"), flow_provider)\n",
    "\n",
    "    if ignore_suffix:\n",
    "        flow_file_names = [\n",
    "            p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)\n",
    "        ]\n",
    "    else:\n",
    "        flow_file_names = os.listdir(flows_dir)\n",
    "    ret_codes = []\n",
    "    exit_code = 0\n",
    "    for flow_file_name in flow_file_names:\n",
    "        flow_name = os.path.basename(flow_file_name)\n",
    "        if flow_file_name.startswith(\"_sciflow\"):\n",
    "            continue\n",
    "        if flow_file_name.endswith(\".py\"):\n",
    "            ret_code, output = check_call_flow(\n",
    "                Path(flows_dir, flow_file_name), flow_command=flow_command\n",
    "            )\n",
    "            flow_results[flow_name] = ret_code, output\n",
    "            if ret_code == 0:\n",
    "                print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "                )\n",
    "            ret_codes.append(ret_code)\n",
    "    if any([rc != 0 for rc in ret_codes]):\n",
    "        exit_code = 1\n",
    "        try:\n",
    "            # Exit with an error code if running from a non interactive Python environment.\n",
    "            get_ipython().__class__.__name__\n",
    "        except NameError:\n",
    "            if exit_on_error:\n",
    "                return sys.exit(exit_code)\n",
    "    return exit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_multistep.py --no-pylint run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "check_call_flows(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_command=\"--no-pylint run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"), flow_provider=\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.5.2 executing TestMultistepFlow for user:'Donal Simmie'\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint is happy!\n",
      "2022-05-11 06:30:30.209 Workflow starting (run-id 1652250629954348):\n",
      "2022-05-11 06:30:30.274 [1652250629954348/start/1 (pid 9578)] Task is starting.\n",
      "2022-05-11 06:30:31.654 [1652250629954348/start/1 (pid 9578)] The first step\n",
      "2022-05-11 06:30:32.036 [1652250629954348/start/1 (pid 9578)] Task finished successfully.\n",
      "2022-05-11 06:30:32.127 [1652250629954348/preprocess/2 (pid 9585)] Task is starting.\n",
      "2022-05-11 06:30:33.491 [1652250629954348/preprocess/2 (pid 9585)] I captialised the message: THE FIRST STEP\n",
      "2022-05-11 06:30:33.904 [1652250629954348/preprocess/2 (pid 9585)] Task finished successfully.\n",
      "2022-05-11 06:30:33.990 [1652250629954348/fit/3 (pid 9592)] Task is starting.\n",
      "2022-05-11 06:30:35.750 [1652250629954348/fit/3 (pid 9592)] Task finished successfully.\n",
      "2022-05-11 06:30:35.831 [1652250629954348/evaluate/4 (pid 9599)] Task is starting.\n",
      "2022-05-11 06:30:37.633 [1652250629954348/evaluate/4 (pid 9599)] Task finished successfully.\n",
      "2022-05-11 06:30:37.718 [1652250629954348/end/5 (pid 9606)] Task is starting.\n",
      "2022-05-11 06:30:39.552 [1652250629954348/end/5 (pid 9606)] Task finished successfully.\n",
      "2022-05-11 06:30:39.566 Done!\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "nb_path = Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\")\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path,\n",
    "    flow_command=\"run\",\n",
    "    params={\"traffic_percent\": 1, \"model_level\": \"dispatcher\"},\n",
    ")\n",
    "print(output)\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aynsc Flow Running\n",
    "\n",
    "> Run the flow you are working on from the notebook you are working on. This maximises the amount of experiments you can run as you don't have down time. While long running tasks are running you can keep exploring! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def flow_task(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"run\", params=None\n",
    "):\n",
    "    cmd = make_shell_cmd(flow_nb_path, flow_provider, flow_command, params)\n",
    "\n",
    "    proc = await asyncio.create_subprocess_shell(\n",
    "        cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    stdout, stderr = await proc.communicate()\n",
    "\n",
    "    # print(f\"[{cmd!r} exited with {proc.returncode}]\")\n",
    "    err = \"\"\n",
    "    out = \"\"\n",
    "    if stderr:\n",
    "        err = f'[stderr]\\n{stderr.decode(\"utf-8\").strip()}'\n",
    "    if stdout:\n",
    "        out = f'[stdout]\\n{stdout.decode(\"utf-8\").strip()}'\n",
    "\n",
    "    return proc.returncode, err + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_flow_async(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"run\", params=None\n",
    "):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(\n",
    "        flow_task(flow_nb_path, flow_provider, flow_command, params)\n",
    "    )\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-4' coro=<flow_task() running at /tmp/ipykernel_8935/3217104127.py:3>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\"),\n",
    "    params={\"traffic_percent\": 10, \"workers\": 12},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-16' coro=<flow_task() running at /tmp/ipykernel_8935/2576585770.py:3>>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_export.ipynb\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    params={\"some_param\": \"async\"},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-22' coro=<flow_task() running at /tmp/ipykernel_8935/2576585770.py:3>>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    params={\"traffic_percent\": 10, \"workers\": 12},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def run_flows_async(\n",
    "    config,\n",
    "    flow_provider=\"metaflow\",\n",
    "    flow_command=\"run\",\n",
    "    params=None,\n",
    "    ignore_suffix=None,\n",
    "    exit_on_error=True,\n",
    "):\n",
    "    flow_tasks = {}\n",
    "    flows_dir = Path(config.path(\"flows_path\"), flow_provider)\n",
    "\n",
    "    if ignore_suffix:\n",
    "        flow_file_names = [\n",
    "            p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)\n",
    "        ]\n",
    "    else:\n",
    "        flow_file_names = os.listdir(flows_dir)\n",
    "    ret_codes = []\n",
    "    exit_code = 0\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    for flow_file_name in flow_file_names:\n",
    "        flow_name = os.path.basename(flow_file_name)\n",
    "        if flow_file_name.startswith(\"_sciflow\"):\n",
    "            continue\n",
    "        if flow_file_name.endswith(\".py\"):\n",
    "            task = loop.create_task(\n",
    "                flow_task(\n",
    "                    Path(flows_dir, flow_file_name), flow_provider, flow_command, params\n",
    "                )\n",
    "            )\n",
    "            flow_tasks[flow_name] = task\n",
    "\n",
    "    for flow_name, task in flow_tasks.items():\n",
    "        await task\n",
    "        ret_code = task.result()[0]\n",
    "        if ret_code == 0:\n",
    "            print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "            )\n",
    "        ret_codes.append(ret_code)\n",
    "    if any([rc != 0 for rc in ret_codes]):\n",
    "        exit_code = 1\n",
    "        try:\n",
    "            # Exit with an error code if running from a non interactive Python environment.\n",
    "            get_ipython().__class__.__name__\n",
    "        except NameError:\n",
    "            if exit_on_error:\n",
    "                return sys.exit(exit_code)\n",
    "    return exit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flows_async(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_command=\"--no-pylint run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_multistep.py --no-pylint run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "task = run_flows_async(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    flow_command=\"run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py run verified\n",
      "Flow: test_data_handling.py run verified\n",
      "Flow: test_module.py run verified\n",
      "Flow: test_multistep.py run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "await task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities to Search Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"traffic_percent\": [1, 5, 10, 20, 50, 100],\n",
    "    \"model_level\": [\"router\", \"dispatcher\"],\n",
    "    \"workers\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def iter_param_grid(param_grid):\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/model_selection/_search.py\n",
    "    for p in [param_grid]:\n",
    "        # Always sort the keys of a dictionary, for reproducibility\n",
    "        items = sorted(p.items())\n",
    "        if not items:\n",
    "            yield {}\n",
    "        else:\n",
    "            keys, values = zip(*items)\n",
    "            for v in product(*values):\n",
    "                params = dict(zip(keys, v))\n",
    "                yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [{\"a\": 1, \"b\": 1, \"c\": \"hello\"}, {\"a\": 2, \"b\": 1, \"c\": \"hello\"}] == list(\n",
    "    iter_param_grid({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def sample_grid_space(param_grid: Dict[str, Iterable[Any]], num_samples: int):\n",
    "    samples = []\n",
    "    for i, sample in enumerate(iter_param_grid(param_grid)):\n",
    "        samples.append(sample)\n",
    "    if num_samples < len(samples):\n",
    "        samples = pd.Series(samples).sample(num_samples).tolist()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = sample_grid_space({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]}, 1)\n",
    "assert sample_space[0][\"b\"] == 1\n",
    "assert sample_space[0][\"c\"] == \"hello\"\n",
    "assert sample_space[0][\"a\"] == 1 or sample_space[0][\"a\"] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "async def search_batches(flow_nb_path, flow_provider, task_batches):\n",
    "    futures = []\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for task_batch in task_batches:\n",
    "        tasks = [\n",
    "            (\n",
    "                loop.create_task(\n",
    "                    flow_task(\n",
    "                        flow_nb_path,\n",
    "                        flow_provider,\n",
    "                        flow_command=\"run\",\n",
    "                        params=param_spec,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            for param_spec in task_batch\n",
    "        ]\n",
    "        futures.append(await asyncio.wait(tasks))\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def search_flow_grid(\n",
    "    flow_nb_path,\n",
    "    param_grid,\n",
    "    flow_provider=\"metaflow\",\n",
    "    total_tasks=None,\n",
    "    n_conc_tasks=None,\n",
    "    local_mode=True,\n",
    "):\n",
    "    if total_tasks is None:\n",
    "        total_tasks = len(list(iter_param_grid(param_grid)))\n",
    "\n",
    "    if local_mode and n_conc_tasks is None:\n",
    "        n_conc_tasks = int((multiprocessing.cpu_count() / 2) - 1)\n",
    "\n",
    "    sample_space = sample_grid_space(param_grid, total_tasks)\n",
    "    task_batches = list(chunks(sample_space, n_conc_tasks))\n",
    "    futures = search_batches(flow_nb_path, flow_provider, task_batches)\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def extract_results(future_tasks):\n",
    "    completed_tasks = [\n",
    "        item for sublist in [list(ft[0]) for ft in future_tasks] for item in sublist\n",
    "    ]\n",
    "    results = [t.result() for t in completed_tasks]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(\n",
    "    Path(\".\").resolve(),\n",
    "    \"test\",\n",
    "    \"test_export.ipynb\",\n",
    ")\n",
    "param_grid = {\n",
    "    \"traffic_percent\": [1, 2, 3, 4, 5, 7, 8, 10, 20, 30, 40, 50],\n",
    "    \"model_level\": [\"dispatcher\"],\n",
    "    \"workers\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "future_tasks = await ensure_future(\n",
    "    search_flow_grid(\n",
    "        nb_path,\n",
    "        param_grid,\n",
    "        flow_provider=\"sagemaker\",\n",
    "        total_tasks=None,\n",
    "        n_conc_tasks=4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-export) already exists.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 226, in upsert\\n    response = self.update(role_arn, description)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 196, in update\\n    return self.sagemaker_session.sagemaker_client.update_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.errorfactory.ConflictException: An error occurred (ConflictException) when calling the UpdatePipeline operation: Pipeline arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export has been modified since your last read.'),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-15-52-44-473\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/x1ugb8obbn4e', 'PipelineExecutionDisplayName': 'execution-1652284367813', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 15, 52, 47, 642000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 15, 52, 47, 642000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': 'a83461c2-7b97-4b1d-90c1-47bb8fa6e040', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'a83461c2-7b97-4b1d-90c1-47bb8fa6e040', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 15:52:47 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-export) already exists.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 226, in upsert\\n    response = self.update(role_arn, description)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 196, in update\\n    return self.sagemaker_session.sagemaker_client.update_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.errorfactory.ConflictException: An error occurred (ConflictException) when calling the UpdatePipeline operation: Pipeline arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export has been modified since your last read.'),\n",
       " (1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the CreatePipeline operation (reached max retries: 4): Rate exceeded'),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-15-57-55-942\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/9knqf5h1g2rx', 'PipelineExecutionDisplayName': 'execution-1652284679272', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 15, 57, 59, 174000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 15, 57, 59, 174000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '74a0397e-d334-4dda-8a25-30520799785d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '74a0397e-d334-4dda-8a25-30520799785d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 15:57:59 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-15-57-55-953\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/q1xgqoxcru09', 'PipelineExecutionDisplayName': 'execution-1652284688208', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 15, 58, 8, 118000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 15, 58, 8, 118000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '3ff5488e-8d99-4d95-84d7-e62564b32f5a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3ff5488e-8d99-4d95-84d7-e62564b32f5a', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 15:58:08 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-export) already exists.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 226, in upsert\\n    response = self.update(role_arn, description)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 196, in update\\n    return self.sagemaker_session.sagemaker_client.update_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.errorfactory.ConflictException: An error occurred (ConflictException) when calling the UpdatePipeline operation: Pipeline arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export has been modified since your last read.'),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-15-57-55-934\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/650e1kwhx13l', 'PipelineExecutionDisplayName': 'execution-1652284689859', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 15, 58, 9, 750000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 15, 58, 9, 750000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': 'e35118dd-6392-47a7-99c1-d4c35b086dc2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e35118dd-6392-47a7-99c1-d4c35b086dc2', 'content-type': 'application/x-amz-json-1.1', 'content-length': '679', 'date': 'Wed, 11 May 2022 15:58:09 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-16-03-46-434\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/6tw9m5zsiqnf', 'PipelineExecutionDisplayName': 'execution-1652285034571', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 16, 3, 54, 481000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 16, 3, 54, 481000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '07eff27a-3758-41ac-97e2-86ce8f319420', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '07eff27a-3758-41ac-97e2-86ce8f319420', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 16:03:54 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-export) already exists.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 226, in upsert\\n    response = self.update(role_arn, description)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 196, in update\\n    return self.sagemaker_session.sagemaker_client.update_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.errorfactory.ConflictException: An error occurred (ConflictException) when calling the UpdatePipeline operation: Pipeline arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export has been modified since your last read.'),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-16-03-46-414\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/87bxxs0k3an7', 'PipelineExecutionDisplayName': 'execution-1652285039021', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 16, 3, 58, 915000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 16, 3, 58, 915000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '9d115648-6bc1-4169-914e-8343c41e9468', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9d115648-6bc1-4169-914e-8343c41e9468', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 16:03:58 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-16-03-46-425\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/i93r6kbhd6f3', 'PipelineExecutionDisplayName': 'execution-1652285029843', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 16, 3, 49, 661000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 16, 3, 49, 661000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': '3791ea0b-ead6-484f-870d-0e48a125ff39', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3791ea0b-ead6-484f-870d-0e48a125ff39', 'content-type': 'application/x-amz-json-1.1', 'content-length': '681', 'date': 'Wed, 11 May 2022 16:03:49 GMT'}, 'RetryAttempts': 0}}\"),\n",
       " (1,\n",
       "  '[stderr]\\nTraceback (most recent call last):\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 219, in upsert\\n    response = self.create(role_arn, description, tags, parallelism_config)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 121, in create\\n    return self.sagemaker_session.sagemaker_client.create_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-export) already exists.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 242, in <module>\\n    flow.run()\\n  File \"/home/sagemaker-user/git/sciflow/nbs/test/flows/sagemaker/test_export.py\", line 225, in run\\n    pipeline.upsert(role_arn=self.role)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 226, in upsert\\n    response = self.update(role_arn, description)\\n  File \"/opt/conda/envs/kernel-env/lib/python3.9/site-packages/sagemaker/workflow/pipeline.py\", line 196, in update\\n    return self.sagemaker_session.sagemaker_client.update_pipeline(**kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 391, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n  File \"/home/sagemaker-user/.local/lib/python3.9/site-packages/botocore/client.py\", line 719, in _make_api_call\\n    raise error_class(parsed_response, operation_name)\\nbotocore.errorfactory.ConflictException: An error occurred (ConflictException) when calling the UpdatePipeline operation: Pipeline arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export has been modified since your last read.'),\n",
       " (0,\n",
       "  \"[stdout]\\nStarting Sciflow generated pipeline: pipeline-2022-05-11-16-09-06-634\\n{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:368653567616:pipeline/test-export/execution/w7qsbmkj1lqt', 'PipelineExecutionDisplayName': 'execution-1652285349938', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2022, 5, 11, 16, 9, 9, 870000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2022, 5, 11, 16, 9, 9, 870000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:368653567616:user-profile/d-likrmmebxomz/donal', 'UserProfileName': 'donal', 'DomainId': 'd-likrmmebxomz'}, 'ResponseMetadata': {'RequestId': 'b5edac50-b53c-4a01-99f1-08544e3cf6f7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b5edac50-b53c-4a01-99f1-08544e3cf6f7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '679', 'date': 'Wed, 11 May 2022 16:09:09 GMT'}, 'RetryAttempts': 0}}\")]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "results = extract_results(future_tasks)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_metaflows():\n",
    "    check_call_flows(get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_sagemaker_flows():\n",
    "    check_call_flows(get_config(), flow_provider=\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_metaflows():\n",
    "    check_call_flows(get_config(), flow_command=\"--no-pylint run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_sagemaker_flows():\n",
    "    check_call_flows(get_config(), flow_command=\"run\", flow_provider=\"sagemaker\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "sciflow (sciflow/3)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:368653567616:image-version/sciflow/3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
