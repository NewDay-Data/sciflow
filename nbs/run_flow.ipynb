{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: run_flow.html\n",
    "title: Verify and Run Sciflow Flows\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | default_exp run_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable\n",
    "\n",
    "import pandas as pd\n",
    "from execnb.nbio import read_nb\n",
    "from fastcore.script import call_parse\n",
    "from nbdev.config import get_config\n",
    "\n",
    "from sciflow.utils import (\n",
    "    chunks,\n",
    "    find_default_export,\n",
    "    get_flow_path,\n",
    "    prepare_env,\n",
    "    run_shell_cmd,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_path = Path(Path(\".\").resolve(), \"test\", \"test_export.ipynb\")\n",
    "flow_path = get_flow_path(nb_path, flow_provider=\"sagemaker\")\n",
    "nb = read_nb(nb_path)\n",
    "module_name = find_default_export(nb[\"cells\"]).replace(\".\", \"/\")\n",
    "test_module = os.path.join(get_config().path(\"lib_path\"), f\"{module_name}.py\")\n",
    "flows_dir = get_config(cfg_name=\"test/settings.ini\").path(\"flows_path\")\n",
    "flow_name = os.path.basename(test_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `check_is_init`\n",
    "\n",
    "check if `scilint_lint` has been called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def check_is_init():\n",
    "    root_path = str(get_config().path(\"root_path\"))\n",
    "\n",
    "    if root_path not in sys.path:\n",
    "        print(f\"PYTHONPATH={sys.path}\")\n",
    "        raise ValueError(\"Project is not in path; have you run sciflow_init?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `make_shell_cmd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def make_shell_cmd(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"show\", params=None\n",
    "):\n",
    "    prepare_env()\n",
    "    if flow_nb_path.suffix == \".ipynb\":\n",
    "        flow_path = get_flow_path(flow_nb_path, flow_provider=flow_provider)\n",
    "    else:\n",
    "        flow_path = flow_nb_path\n",
    "    if params:\n",
    "        args = \" \".join([f\"--{k} {v}\" for k, v in params.items()])\n",
    "\n",
    "        flow_command = f\"{flow_command} {args}\"\n",
    "\n",
    "    return f\"python '{flow_path}' {flow_command}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Verify or Run an Individual Flow\n",
    "\n",
    "> `subprocess` is used to run flows as most flow providers bundle a CLI which makes for a consistent execution experience with minimal adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `check_call_flow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def check_call_flow(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"show\", params=None\n",
    "):\n",
    "    check_is_init()\n",
    "\n",
    "    cmd = make_shell_cmd(flow_nb_path, flow_provider, flow_command, params)\n",
    "    pipe, output = run_shell_cmd(cmd)\n",
    "    return pipe.returncode, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_path = sys.path\n",
    "sys.path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH=[]\n"
     ]
    }
   ],
   "source": [
    "raised = False\n",
    "try:\n",
    "    check_call_flow(nb_path, flow_provider=\"metaflow\", flow_command=\"show\")\n",
    "except:\n",
    "    raised = True\n",
    "assert raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path = sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"metaflow\", flow_command=\"show\"\n",
    ")\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.10.0 executing TestExportFlow for user:Donal Simmie\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "2023-10-24 21:00:50.977 Workflow starting (run-id 1698181250579620):\n",
      "2023-10-24 21:00:51.104 [1698181250579620/start/1 (pid 830)] Task is starting.\n",
      "2023-10-24 21:00:55.720 [1698181250579620/start/1 (pid 830)] 3\n",
      "2023-10-24 21:00:56.119 [1698181250579620/start/1 (pid 830)] Task finished successfully.\n",
      "2023-10-24 21:00:56.295 [1698181250579620/preprocess/2 (pid 834)] Task is starting.\n",
      "2023-10-24 21:01:00.917 [1698181250579620/preprocess/2 (pid 834)] Preprocessing input data from /home/sagemaker-user/git/sciflow/nbs...\n",
      "2023-10-24 21:01:02.495 [1698181250579620/preprocess/2 (pid 834)] Task finished successfully.\n",
      "2023-10-24 21:01:02.694 [1698181250579620/train/3 (pid 846)] Task is starting.\n",
      "2023-10-24 21:01:07.439 [1698181250579620/train/3 (pid 846)] Training /home/sagemaker-user/git/sciflow on /home/sagemaker-user/git/sciflow/nbs...\n",
      "2023-10-24 21:01:08.812 [1698181250579620/train/3 (pid 846)] Task finished successfully.\n",
      "2023-10-24 21:01:08.978 [1698181250579620/end/4 (pid 852)] Task is starting.\n",
      "2023-10-24 21:01:13.967 [1698181250579620/end/4 (pid 852)] Task finished successfully.\n",
      "2023-10-24 21:01:13.990 Done!\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"metaflow\", flow_command=\"run\"\n",
    ")\n",
    "assert ret_code == 0\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.10.0 executing TestExportFlow for user:Donal Simmie\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "2023-10-24 21:01:19.131 Workflow starting (run-id 1698181278746993):\n",
      "2023-10-24 21:01:19.260 [1698181278746993/start/1 (pid 881)] Task is starting.\n",
      "2023-10-24 21:01:23.876 [1698181278746993/start/1 (pid 881)] 3\n",
      "2023-10-24 21:01:24.269 [1698181278746993/start/1 (pid 881)] Task finished successfully.\n",
      "2023-10-24 21:01:24.445 [1698181278746993/preprocess/2 (pid 885)] Task is starting.\n",
      "2023-10-24 21:01:29.061 [1698181278746993/preprocess/2 (pid 885)] Preprocessing input data from /home/sagemaker-user/git/sciflow/nbs...\n",
      "2023-10-24 21:01:30.440 [1698181278746993/preprocess/2 (pid 885)] Task finished successfully.\n",
      "2023-10-24 21:01:30.621 [1698181278746993/train/3 (pid 889)] Task is starting.\n",
      "2023-10-24 21:01:35.225 [1698181278746993/train/3 (pid 889)] Training /home/sagemaker-user/git/sciflow on /home/sagemaker-user/git/sciflow/nbs...\n",
      "2023-10-24 21:01:36.621 [1698181278746993/train/3 (pid 889)] Task finished successfully.\n",
      "2023-10-24 21:01:36.772 [1698181278746993/end/4 (pid 893)] Task is starting.\n",
      "2023-10-24 21:01:41.744 [1698181278746993/end/4 (pid 893)] Task finished successfully.\n",
      "2023-10-24 21:01:41.760 Done!\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "ret_code, output = check_call_flow(nb_path, flow_command=\"run\")\n",
    "assert ret_code == 0\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"sagemaker\", flow_command=\"show\"\n",
    ")\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/utils.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/utils.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/export_step.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/export_step.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/packaging.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/packaging.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/s3_utils.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/s3_utils.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/run_flow.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/run_flow.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/_modidx.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/_modidx.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/init.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/init.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/params.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/params.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/__init__.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/__init__.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/parse_module.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/parse_module.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_export.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_export.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_data_handling.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_data_handling.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_module.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_module.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_multistep_no_params.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_multistep_no_params.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_multistep.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_multistep.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/test_export_params.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/test_export_params.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/test/__init__.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/test/__init__.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/converters/to_metaflow.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/converters/to_metaflow.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/converters/to_sagemaker.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/converters/to_sagemaker.py\n",
      "Uploading file: /home/sagemaker-user/git/sciflow/sciflow/converters/__init__.py to: prosandboxpdlras3/test_export/pipeline-2023-10-24-21-01-57-123/code/sciflow/converters/__init__.py\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Starting Sciflow generated pipeline: pipeline-2023-10-24-21-01-57-123\n",
      "{'PipelineArn': 'arn:aws:sagemaker:eu-west-1:823878111748:pipeline/test-export', 'PipelineExecutionArn': 'arn:aws:sagemaker:eu-west-1:823878111748:pipeline/test-export/execution/cg79ggaca2b2', 'PipelineExecutionDisplayName': 'execution-1698181320064', 'PipelineExecutionStatus': 'Executing', 'CreationTime': datetime.datetime(2023, 10, 24, 21, 2, 0, 7000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2023, 10, 24, 21, 2, 0, 7000, tzinfo=tzlocal()), 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:823878111748:user-profile/d-stp2tis5kcgj/donals', 'UserProfileName': 'donals', 'DomainId': 'd-stp2tis5kcgj'}, 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:eu-west-1:823878111748:user-profile/d-stp2tis5kcgj/donals', 'UserProfileName': 'donals', 'DomainId': 'd-stp2tis5kcgj'}, 'ResponseMetadata': {'RequestId': '8c77b729-8dc6-40b2-ba7a-5616d6a12f84', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '8c77b729-8dc6-40b2-ba7a-5616d6a12f84', 'content-type': 'application/x-amz-json-1.1', 'content-length': '685', 'date': 'Tue, 24 Oct 2023 21:01:59 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path, flow_provider=\"sagemaker\", flow_command=\"run\"\n",
    ")\n",
    "print(output)\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify/Run all Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `check_call_flows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def check_call_flows(\n",
    "    config,\n",
    "    flow_provider=\"metaflow\",\n",
    "    flow_command=\"show\",\n",
    "    ignore_suffix=None,\n",
    "    exit_on_error=True,\n",
    "):\n",
    "    flow_results = {}\n",
    "    flows_dir = Path(config.path(\"flows_path\"), flow_provider)\n",
    "\n",
    "    if ignore_suffix:\n",
    "        flow_file_names = [\n",
    "            p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)\n",
    "        ]\n",
    "    else:\n",
    "        flow_file_names = os.listdir(flows_dir)\n",
    "    ret_codes = []\n",
    "    exit_code = 0\n",
    "    for flow_file_name in flow_file_names:\n",
    "        flow_name = os.path.basename(flow_file_name)\n",
    "        if flow_file_name.startswith(\"_sciflow\"):\n",
    "            continue\n",
    "        if flow_file_name.endswith(\".py\"):\n",
    "            ret_code, output = check_call_flow(\n",
    "                Path(flows_dir, flow_file_name), flow_command=flow_command\n",
    "            )\n",
    "            flow_results[flow_name] = ret_code, output\n",
    "            if ret_code == 0:\n",
    "                print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "                )\n",
    "            ret_codes.append(ret_code)\n",
    "    if any([rc != 0 for rc in ret_codes]):\n",
    "        exit_code = 1\n",
    "        try:\n",
    "            # Exit with an error code if running from a non interactive Python environment.\n",
    "            get_ipython().__class__.__name__\n",
    "        except NameError:\n",
    "            if exit_on_error:\n",
    "                return sys.exit(exit_code)\n",
    "    return exit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_multistep.py --no-pylint run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "check_call_flows(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_command=\"--no-pylint run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py show verified\n",
      "Flow: test_data_handling.py show verified\n",
      "Flow: test_module.py show verified\n",
      "Flow: test_multistep_no_params.py show verified\n",
      "Flow: test_multistep.py show verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_call_flows(get_config(cfg_name=\"test/settings.ini\"), flow_provider=\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaflow 2.10.0 executing TestMultistepFlow for user:Donal Simmie\n",
      "Validating your flow...\n",
      "    The graph looks good!\n",
      "Running pylint...\n",
      "    Pylint not found, so extra checks are disabled.\n",
      "2023-10-24 21:07:48.121 Workflow starting (run-id 1698181667755156):\n",
      "2023-10-24 21:07:48.256 [1698181667755156/start/1 (pid 1341)] Task is starting.\n",
      "2023-10-24 21:07:49.120 [1698181667755156/start/1 (pid 1341)] The first step\n",
      "2023-10-24 21:07:49.560 [1698181667755156/start/1 (pid 1341)] Task finished successfully.\n",
      "2023-10-24 21:07:49.718 [1698181667755156/preprocess/2 (pid 1346)] Task is starting.\n",
      "2023-10-24 21:07:50.591 [1698181667755156/preprocess/2 (pid 1346)] I captialised the message: THE FIRST STEP\n",
      "2023-10-24 21:07:51.055 [1698181667755156/preprocess/2 (pid 1346)] Task finished successfully.\n",
      "2023-10-24 21:07:51.210 [1698181667755156/fit/3 (pid 1351)] Task is starting.\n",
      "2023-10-24 21:07:52.537 [1698181667755156/fit/3 (pid 1351)] Task finished successfully.\n",
      "2023-10-24 21:07:52.689 [1698181667755156/end/4 (pid 1356)] Task is starting.\n",
      "2023-10-24 21:07:54.069 [1698181667755156/end/4 (pid 1356)] Task finished successfully.\n",
      "2023-10-24 21:07:54.087 Done!\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "nb_path = Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\")\n",
    "ret_code, output = check_call_flow(\n",
    "    nb_path,\n",
    "    flow_command=\"run\",\n",
    "    params={\"traffic_percent\": 1, \"model_level\": \"dispatcher\"},\n",
    ")\n",
    "print(output)\n",
    "assert ret_code == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Aynsc Flow Running\n",
    "\n",
    "> Run the flow you are working on from the notebook you are working on. This maximises the amount of experiments you can run as you don't have down time. While long running tasks are running you can keep exploring! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `flow_task`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def flow_task(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"run\", params=None\n",
    "):\n",
    "    cmd = make_shell_cmd(flow_nb_path, flow_provider, flow_command, params)\n",
    "\n",
    "    proc = await asyncio.create_subprocess_shell(\n",
    "        cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    stdout, stderr = await proc.communicate()\n",
    "\n",
    "    err = \"\"\n",
    "    out = \"\"\n",
    "    if stderr:\n",
    "        err = f'[stderr]\\n{stderr.decode(\"utf-8\").strip()}'\n",
    "    if stdout:\n",
    "        out = f'[stdout]\\n{stdout.decode(\"utf-8\").strip()}'\n",
    "\n",
    "    return proc.returncode, err + out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `run_flow_async`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def run_flow_async(\n",
    "    flow_nb_path, flow_provider=\"metaflow\", flow_command=\"run\", params=None\n",
    "):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    task = loop.create_task(\n",
    "        flow_task(flow_nb_path, flow_provider, flow_command, params)\n",
    "    )\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-10' coro=<flow_task() running at /tmp/ipykernel_797/613685200.py:4>>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\"),\n",
    "    params={\"traffic_percent\": 10, \"workers\": 12},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-16' coro=<flow_task() running at /tmp/ipykernel_797/613685200.py:4>>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_export.ipynb\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    params={\"some_param\": \"async\"},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-22' coro=<flow_task() running at /tmp/ipykernel_797/613685200.py:4>>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "task = run_flow_async(\n",
    "    Path(Path(\".\").resolve(), \"test\", \"test_multistep.ipynb\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    params={\"traffic_percent\": 10, \"workers\": 12},\n",
    ")\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# | notest\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m==\u001b[39m task\u001b[38;5;241m.\u001b[39mresult()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "await task\n",
    "assert 0 == task.result()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `run_flows_async`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def run_flows_async(\n",
    "    config,\n",
    "    flow_provider=\"metaflow\",\n",
    "    flow_command=\"run\",\n",
    "    params=None,\n",
    "    ignore_suffix=None,\n",
    "    exit_on_error=True,\n",
    "):\n",
    "    flow_tasks = {}\n",
    "    flows_dir = Path(config.path(\"flows_path\"), flow_provider)\n",
    "\n",
    "    if ignore_suffix:\n",
    "        flow_file_names = [\n",
    "            p for p in os.listdir(flows_dir) if not p.endswith(ignore_suffix)\n",
    "        ]\n",
    "    else:\n",
    "        flow_file_names = os.listdir(flows_dir)\n",
    "    ret_codes = []\n",
    "    exit_code = 0\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    for flow_file_name in flow_file_names:\n",
    "        flow_name = os.path.basename(flow_file_name)\n",
    "        if flow_file_name.startswith(\"_sciflow\"):\n",
    "            continue\n",
    "        if flow_file_name.endswith(\".py\"):\n",
    "            task = loop.create_task(\n",
    "                flow_task(\n",
    "                    Path(flows_dir, flow_file_name), flow_provider, flow_command, params\n",
    "                )\n",
    "            )\n",
    "            flow_tasks[flow_name] = task\n",
    "\n",
    "    for flow_name, task in flow_tasks.items():\n",
    "        await task\n",
    "        ret_code = task.result()[0]\n",
    "        if ret_code == 0:\n",
    "            print(f\"Flow: {flow_name} {flow_command} verified\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Flow: {flow_name} {flow_command} verification failed\\nDetails:\\n{output}\"\n",
    "            )\n",
    "        ret_codes.append(ret_code)\n",
    "    if any([rc != 0 for rc in ret_codes]):\n",
    "        exit_code = 1\n",
    "        try:\n",
    "            # Exit with an error code if running from a non interactive Python environment.\n",
    "            get_ipython().__class__.__name__\n",
    "        except NameError:\n",
    "            if exit_on_error:\n",
    "                return sys.exit(exit_code)\n",
    "    return exit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "task = run_flows_async(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_command=\"--no-pylint run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py --no-pylint run verified\n",
      "Flow: test_data_handling.py --no-pylint run verified\n",
      "Flow: test_module.py --no-pylint run verified\n",
      "Flow: test_multistep.py --no-pylint run verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "task = run_flows_async(\n",
    "    get_config(cfg_name=\"test/settings.ini\"),\n",
    "    flow_provider=\"sagemaker\",\n",
    "    flow_command=\"run\",\n",
    "    ignore_suffix=\"_no_params.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow: test_export.py run verified\n",
      "Flow: test_data_handling.py run verified\n",
      "Flow: test_module.py run verified\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "await task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities to Search Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"traffic_percent\": [1, 5, 10, 20, 50, 100],\n",
    "    \"model_level\": [\"router\", \"dispatcher\"],\n",
    "    \"workers\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `iter_param_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def iter_param_grid(param_grid):\n",
    "    # https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/model_selection/_search.py\n",
    "    for p in [param_grid]:\n",
    "        # Always sort the keys of a dictionary, for reproducibility\n",
    "        items = sorted(p.items())\n",
    "        if not items:\n",
    "            yield {}\n",
    "        else:\n",
    "            keys, values = zip(*items)\n",
    "            for v in product(*values):\n",
    "                params = dict(zip(keys, v))\n",
    "                yield params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [{\"a\": 1, \"b\": 1, \"c\": \"hello\"}, {\"a\": 2, \"b\": 1, \"c\": \"hello\"}] == list(\n",
    "    iter_param_grid({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sample_grid_space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def sample_grid_space(param_grid: Dict[str, Iterable[Any]], num_samples: int):\n",
    "    samples = []\n",
    "    for i, sample in enumerate(iter_param_grid(param_grid)):\n",
    "        samples.append(sample)\n",
    "    if num_samples < len(samples):\n",
    "        samples = pd.Series(samples).sample(num_samples).tolist()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = sample_grid_space({\"a\": [1, 2], \"b\": [1], \"c\": [\"hello\"]}, 1)\n",
    "assert sample_space[0][\"b\"] == 1\n",
    "assert sample_space[0][\"c\"] == \"hello\"\n",
    "assert sample_space[0][\"a\"] == 1 or sample_space[0][\"a\"] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `search_batches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def search_batches(flow_nb_path, flow_provider, task_batches):\n",
    "    futures = []\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for task_batch in task_batches:\n",
    "        tasks = [\n",
    "            (\n",
    "                loop.create_task(\n",
    "                    flow_task(\n",
    "                        flow_nb_path,\n",
    "                        flow_provider,\n",
    "                        flow_command=\"run\",\n",
    "                        params=param_spec,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            for param_spec in task_batch\n",
    "        ]\n",
    "        futures.append(await asyncio.wait(tasks))\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `search_flow_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def search_flow_grid(\n",
    "    flow_nb_path,\n",
    "    param_grid,\n",
    "    flow_provider=\"metaflow\",\n",
    "    total_tasks=None,\n",
    "    n_conc_tasks=None,\n",
    "    local_mode=True,\n",
    "):\n",
    "    if total_tasks is None:\n",
    "        total_tasks = len(list(iter_param_grid(param_grid)))\n",
    "\n",
    "    if local_mode and n_conc_tasks is None:\n",
    "        n_conc_tasks = int((multiprocessing.cpu_count() / 2) - 1)\n",
    "\n",
    "    sample_space = sample_grid_space(param_grid, total_tasks)\n",
    "    task_batches = list(chunks(sample_space, n_conc_tasks))\n",
    "    futures = search_batches(flow_nb_path, flow_provider, task_batches)\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `extract_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def extract_results(future_tasks):\n",
    "    completed_tasks = [\n",
    "        item for sublist in [list(ft[0]) for ft in future_tasks] for item in sublist\n",
    "    ]\n",
    "    results = [t.result() for t in completed_tasks]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = Path(\n",
    "    Path(\".\").resolve(),\n",
    "    \"test\",\n",
    "    \"test_export.ipynb\",\n",
    ")\n",
    "param_grid = {\n",
    "    \"traffic_percent\": [1, 2, 3, 4, 5, 7, 8, 10, 20, 30, 40, 50],\n",
    "    \"model_level\": [\"dispatcher\"],\n",
    "    \"workers\": [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "future_tasks = await ensure_future(\n",
    "    search_flow_grid(\n",
    "        nb_path,\n",
    "        param_grid,\n",
    "        flow_provider=\"sagemaker\",\n",
    "        total_tasks=None,\n",
    "        n_conc_tasks=4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "results = extract_results(future_tasks)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sciflow_check_metaflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_metaflows():\n",
    "    check_call_flows(get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sciflow_check_sagemaker_flows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_check_sagemaker_flows():\n",
    "    check_call_flows(get_config(), flow_provider=\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sciflow_run_metaflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_metaflows():\n",
    "    check_call_flows(get_config(), flow_command=\"run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sciflow_run_sagemaker_flows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def sciflow_run_sagemaker_flows():\n",
    "    check_call_flows(get_config(), flow_command=\"run\", flow_provider=\"sagemaker\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:819792524951:image/sagemaker-distribution-cpu-v0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
